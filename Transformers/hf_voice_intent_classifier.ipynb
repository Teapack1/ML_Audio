{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\majoron\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"audio-classification\", model=\"MIT/ast-finetuned-speech-commands-v2\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marvin'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model.config.id2label[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines.audio_utils import ffmpeg_microphone_live\n",
    "\n",
    "\n",
    "def launch_fn(\n",
    "    wake_word=\"marvin\",\n",
    "    prob_threshold=0.5,\n",
    "    chunk_length_s=2.0,\n",
    "    stream_chunk_s=0.25,\n",
    "    debug=False,\n",
    "):\n",
    "    if wake_word not in classifier.model.config.label2id.keys():\n",
    "        raise ValueError(\n",
    "            f\"Wake word {wake_word} not in set of valid class labels, pick a wake word in the set {classifier.model.config.label2id.keys()}.\"\n",
    "        )\n",
    "\n",
    "    sampling_rate = classifier.feature_extractor.sampling_rate\n",
    "\n",
    "    mic = ffmpeg_microphone_live(\n",
    "        sampling_rate=sampling_rate,\n",
    "        chunk_length_s=chunk_length_s,\n",
    "        stream_chunk_s=stream_chunk_s,\n",
    "    )\n",
    "\n",
    "    print(\"Listening for wake word...\")\n",
    "    for prediction in classifier(mic):\n",
    "        prediction = prediction[0]\n",
    "        if debug:\n",
    "            print(prediction)\n",
    "        if prediction[\"label\"] == wake_word:\n",
    "            if prediction[\"score\"] > prob_threshold:\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for wake word...\n",
      "Using microphone: Stolní mikrofon (RØDE NT-USB+)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\majoron\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\audio_spectrogram_transformer\\feature_extraction_audio_spectrogram_transformer.py:96: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  waveform = torch.from_numpy(waveform).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.046502429991960526, 'label': 'off'}\n",
      "{'score': 0.05743061751127243, 'label': 'off'}\n",
      "{'score': 0.08725891262292862, 'label': 'up'}\n",
      "{'score': 0.08726627379655838, 'label': 'off'}\n",
      "{'score': 0.08500546962022781, 'label': 'off'}\n",
      "{'score': 0.08954951912164688, 'label': 'off'}\n",
      "{'score': 0.08954953402280807, 'label': 'off'}\n",
      "{'score': 0.08954954892396927, 'label': 'off'}\n",
      "{'score': 0.7404394149780273, 'label': 'yes'}\n",
      "{'score': 0.999954342842102, 'label': 'marvin'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launch_fn(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at anton-l/xtreme_s_xlsr_minds14 were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at anton-l/xtreme_s_xlsr_minds14 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "intent_class_pipe = pipeline(\n",
    "    \"audio-classification\", model=\"anton-l/xtreme_s_xlsr_minds14\", device=device\n",
    ")\n",
    "\n",
    "# Listens to 2 second chunks, if there is one chunk silence, it will quit loop and concatineate all chunks into one audio file\n",
    "\n",
    "def listen(chunk_length_s=2.0, stream_chunk_s=2.0):\n",
    "    sampling_rate = intent_class_pipe.feature_extractor.sampling_rate\n",
    "\n",
    "\n",
    "    mic = ffmpeg_microphone_live(\n",
    "        sampling_rate=sampling_rate,\n",
    "        chunk_length_s=chunk_length_s,\n",
    "        stream_chunk_s=stream_chunk_s,\n",
    "    )\n",
    "    audio_buffer = []\n",
    "    \n",
    "    print(\"Listening\")\n",
    "    for i in range(5):\n",
    "        audio_chunk = next(mic)\n",
    "        audio_buffer.append(audio_chunk[\"raw\"])\n",
    "        prediction2 = intent_class_pipe(combined_audio)\n",
    "        prediction2 = prediction2[0]\n",
    "        print(prediction2)\n",
    "        \n",
    "        if is_silence(audio_chunk[\"raw\"], threshold=0.7):\n",
    "            print(\"Silence detected, processing audio.\")\n",
    "            break\n",
    "        \n",
    "    combined_audio = np.concatenate(audio_buffer)\n",
    "    prediction = intent_class_pipe(combined_audio)\n",
    "    prediction = prediction[0]\n",
    "    print(prediction)\n",
    "    \n",
    "def is_silence(audio_chunk, threshold):\n",
    "    silence = intent_class_pipe(audio_chunk)\n",
    "    if silence[0][\"label\"] == \"silence\" and silence[0][\"score\"] > threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening\n",
      "Using microphone: Stolní mikrofon (RØDE NT-USB+)\n",
      "{'score': 0.44692686200141907, 'label': 'address'}\n"
     ]
    }
   ],
   "source": [
    "listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'abroad',\n",
       " 1: 'address',\n",
       " 2: 'app_error',\n",
       " 3: 'atm_limit',\n",
       " 4: 'balance',\n",
       " 5: 'business_loan',\n",
       " 6: 'card_issues',\n",
       " 7: 'cash_deposit',\n",
       " 8: 'direct_debit',\n",
       " 9: 'freeze',\n",
       " 10: 'high_value_payment',\n",
       " 11: 'joint_account',\n",
       " 12: 'latest_transactions',\n",
       " 13: 'pay_bill'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_class_pipe.model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for wake word...\n",
      "Using microphone: Stolní mikrofon (RØDE NT-USB+)\n",
      "{'score': 0.04531978443264961, 'label': 'two'}\n",
      "{'score': 0.06030075624585152, 'label': 'off'}\n",
      "{'score': 0.10184475779533386, 'label': 'up'}\n",
      "{'score': 0.41994479298591614, 'label': 'follow'}\n",
      "{'score': 0.28591388463974, 'label': 'follow'}\n",
      "{'score': 0.22937853634357452, 'label': 'follow'}\n",
      "{'score': 0.22937849164009094, 'label': 'follow'}\n",
      "{'score': 0.22937841713428497, 'label': 'follow'}\n",
      "{'score': 0.8394161462783813, 'label': 'marvin'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'listen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m launch_fn(debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlisten\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'listen' is not defined"
     ]
    }
   ],
   "source": [
    "launch_fn(debug=True)\n",
    "listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
