{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import time\n",
    "from IPython.display import Audio\n",
    "#from pydub import AudioSegment\n",
    "#from pydub.playback import play\n",
    "import random\n",
    "#import sounddevice as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check device index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device index: 0, Device name: Microsoft Sound Mapper - Input\n",
      "Device index: 1, Device name: Microphone (High Definition Aud\n",
      "Device index: 2, Device name: Microsoft Sound Mapper - Output\n",
      "Device index: 3, Device name: M237WDP (NVIDIA High Definition\n",
      "Device index: 4, Device name: BenQ GW2470 (NVIDIA High Defini\n",
      "Device index: 5, Device name: Primary Sound Capture Driver\n",
      "Device index: 6, Device name: Microphone (High Definition Audio Device)\n",
      "Device index: 7, Device name: Primary Sound Driver\n",
      "Device index: 8, Device name: M237WDP (NVIDIA High Definition Audio)\n",
      "Device index: 9, Device name: BenQ GW2470 (NVIDIA High Definition Audio)\n",
      "Device index: 10, Device name: BenQ GW2470 (NVIDIA High Definition Audio)\n",
      "Device index: 11, Device name: M237WDP (NVIDIA High Definition Audio)\n",
      "Device index: 12, Device name: Microphone (High Definition Audio Device)\n",
      "Device index: 13, Device name: Microphone (HD Audio Microphone)\n",
      "Device index: 14, Device name: Output (NVIDIA High Definition Audio)\n",
      "Device index: 15, Device name: Output ()\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "    device_info = p.get_device_info_by_index(i)\n",
    "    print(f\"Device index: {i}, Device name: {device_info['name']}\")\n",
    "\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audio dataset\n",
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your desired sample rate (standard is 44100 Hz)\n",
    "SAMPLE_RATE = 16000\n",
    "# Choose your desired duration of recording in seconds\n",
    "DURATION = 1\n",
    "# Classes to record\n",
    "CLASSES = [\"void\", \"on\", \"off\", \"scene1\", \"scene2\", \"scene3\", \"ambient\", \"ambient_theme\", \"light_on\"]\n",
    "# Samples dir:\n",
    "SAMPLES_DIR = \"audio_samples\"\n",
    "if os.path.exists(SAMPLES_DIR) == False:\n",
    "    os.mkdir(SAMPLES_DIR)\n",
    "\n",
    "SAMPLE_COUNT = 20\n",
    "DEVICE_INDEX = 1\n",
    "CHANNELS = 1\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Function - record and collect samples\n",
    "- Collect all in one folder\n",
    "- Samples are named \"class_name_1.wav\", \"class_name_2.wav\" ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio data collection function\n",
    "# All in one Folder:\n",
    "def record_audio(p, SAMPLE_RATE, FORMAT, CHANNELS, CHUNK, DEVICE_INDEX, DURATION, CLASSES):\n",
    "    for cls in CLASSES:\n",
    "        print(\"Recording class: \", cls)\n",
    "        \n",
    "        for sample in range(SAMPLE_COUNT):\n",
    "            print(f\"Recording sample no.: {sample} / {SAMPLE_COUNT}\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            stream = p.open(format = FORMAT,\n",
    "                            channels = CHANNELS,\n",
    "                            rate = SAMPLE_RATE,\n",
    "                            input = True,\n",
    "                            frames_per_buffer = CHUNK,\n",
    "                            input_device_index = DEVICE_INDEX)\n",
    "            frames = []\n",
    "\n",
    "            for i in range(0, int(SAMPLE_RATE / CHUNK * DURATION)):\n",
    "                data = stream.read(CHUNK)\n",
    "                frames.append(np.frombuffer(data, dtype=np.int16))\n",
    "            \n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            \n",
    "            \"\"\"\n",
    "            #playback\n",
    "            print(\"Playback\")\n",
    "            \n",
    "            stream = p.open(format = FORMAT,\n",
    "                            channels = CHANNELS,\n",
    "                            rate = SAMPLE_RATE,\n",
    "                            output = True,\n",
    "                            frames_per_buffer = CHUNK)\n",
    "            \n",
    "            for frame in frames:\n",
    "                stream.write(frame)\n",
    "\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            \"\"\"\n",
    "\n",
    "            record = np.concatenate(frames, axis=0)\n",
    "            record = np.squeeze(record)\n",
    "            # trimmed, index = librosa.effects.trim(record, top_db=15)\n",
    "\n",
    "\n",
    "            #record = librosa.util.normalize(record)\n",
    "\n",
    "            filename = os.path.join(SAMPLES_DIR, f\"{cls}_{sample}.wav\")\n",
    "            sf.write(filename, record, SAMPLE_RATE)\n",
    "            print(\"Saved at: \", filename)\n",
    "            \n",
    "    p.terminate()\n",
    "    print(\"Finished recording.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at:  audio_samples\\void_11.wav\n",
      "Recording sample no.: 12 / 20\n",
      "Saved at:  audio_samples\\void_12.wav\n",
      "Recording sample no.: 13 / 20\n",
      "Saved at:  audio_samples\\void_13.wav\n",
      "Recording sample no.: 14 / 20\n",
      "Saved at:  audio_samples\\void_14.wav\n",
      "Recording sample no.: 15 / 20\n",
      "Saved at:  audio_samples\\void_15.wav\n",
      "Recording sample no.: 16 / 20\n",
      "Saved at:  audio_samples\\void_16.wav\n",
      "Recording sample no.: 17 / 20\n",
      "Saved at:  audio_samples\\void_17.wav\n",
      "Recording sample no.: 18 / 20\n",
      "Saved at:  audio_samples\\void_18.wav\n",
      "Recording sample no.: 19 / 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at:  audio_samples\\void_19.wav\n",
      "Recording class:  on\n",
      "Recording sample no.: 0 / 20\n"
     ]
    }
   ],
   "source": [
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "record_audio(p, SAMPLE_RATE, FORMAT, CHANNELS, CHUNK, DEVICE_INDEX, DURATION, CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Audio Augmentation\n",
    "- Take original samples and multiply them with applying augmentation methods.\n",
    "- Takes samples from common folder and puts augmented ones in another folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAMPLES_DIR = \"audio_samples\"\n",
    "AUG_SAMPLES_DIR = \"augmented_audio_samples\"\n",
    "NUM_AUGMENTED = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = {}\n",
    "\n",
    "for file in os.listdir(SAMPLES_DIR):\n",
    "    #Load file\n",
    "    audio_file = os.path.join(SAMPLES_DIR, file)\n",
    "    print(audio_file)\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Get class name and count\n",
    "    class_name = file.split(\"_\", 1)[0]\n",
    "    if class_name not in class_counts:\n",
    "        class_counts[class_name] = 0\n",
    "\n",
    "    os.makedirs(AUG_SAMPLES_DIR, exist_ok=True)\n",
    "\n",
    "    for i in range(NUM_AUGMENTED):\n",
    "        # Augment image\n",
    "        method = random.choice([\"pitch\", \"stretch\", \"noise\", \"db\"])\n",
    "\n",
    "        if method == \"pitch\":\n",
    "            steps = random.randint(-1, 1)  \n",
    "            augmented = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)\n",
    "\n",
    "        elif method == \"stretch\":\n",
    "            rate = random.uniform(0.9, 1.1)  # Random rate for time stretching\n",
    "            augmented = librosa.effects.time_stretch(y, rate=rate)\n",
    "\n",
    "        elif method == \"noise\":\n",
    "            noise = np.random.normal(0, 0.01, len(y))  # Gaussian noise\n",
    "            augmented = y + noise\n",
    "\n",
    "        elif method == \"db\":\n",
    "            audio_segment = AudioSegment.from_wav(audio_file)\n",
    "            db_change = random.randint(-10, 10)  # Random change in volume (dB)\n",
    "            augmented_segment = audio_segment + db_change\n",
    "            augmented = np.array(augmented_segment.get_array_of_samples())\n",
    "\n",
    "        class_counts[class_name] += 1\n",
    "        new_file = os.path.join(AUG_SAMPLES_DIR, f\"{file.split('_', 1)[0]}_{class_counts[class_name]}.wav\")\n",
    "        sf.write(new_file, augmented, SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate metadata.csv (optional) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory that contains your audio files\n",
    "audio_dir = 'audio_samples'\n",
    "\n",
    "# Get a list of all the audio files in the directory\n",
    "audio_files = os.listdir(audio_dir)\n",
    "\n",
    "# Initialize lists to hold the file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the audio files\n",
    "for file in audio_files:\n",
    "    # Get the full path to the file\n",
    "    file_path = os.path.join(audio_dir, file)\n",
    "    \n",
    "    # Get the label from the filename\n",
    "    label = file.split('_')[0]\n",
    "    \n",
    "    # Add the file path and label to the lists\n",
    "    file_paths.append(file_path)\n",
    "    labels.append(label)\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "df = pd.DataFrame({\n",
    "    'file_name': file_paths,\n",
    "    'transcription': labels\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "AUDIO_FILES = \"augmented_audio_samples\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "all_files = os.listdir(AUDIO_FILES)\n",
    "\n",
    "# Get all classes in a list (without duplicates -> set)\n",
    "classes = list(set([file.split(\"_\", 1)[0] for file in files]))\n",
    "\n",
    "# Create train, test dirs\n",
    "os.makedirs(os.path.join(DATA_DIR, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(DATA_DIR, \"test\"), exist_ok=True)\n",
    "\n",
    "for cls in classes:\n",
    "\n",
    "    # Get all files for a class\n",
    "    class_files = [file for file in all_files if file.startswith(cls)]\n",
    "\n",
    "    # Shuffle files, train test split\n",
    "    np.random.shuffle(class_files)\n",
    "    split_index = int(0.8 * len(class_files))\n",
    "    train_files = class_files[:split_index]\n",
    "    test_files = class_files[split_index:]\n",
    "\n",
    "    # Create train , test dirs for each class\n",
    "    class_train_dir = os.path.join(DATA_DIR, \"train\", cls)\n",
    "    class_test_dir = os.path.join(DATA_DIR, \"test\", cls)\n",
    "    os.makedirs(class_train_dir, exist_ok=True)\n",
    "    os.makedirs(class_test_dir, exist_ok=True)\n",
    "\n",
    "    # Copy files to train, test dirs\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(AUDIO_FILES, file), class_train_dir)\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(AUDIO_FILES, file), class_test_dir)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ******************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Function - record and collect samples\n",
    "- Putting every class in its separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio data collection function \n",
    "# Sorting in separate folders:\n",
    "def record_audio(p, SAMPLE_RATE, FORMAT, CHANNELS, CHUNK, DEVICE_INDEX, DURATION, CLASSES):\n",
    "    for cls in CLASSES:\n",
    "        dir = os.path.join(SAMPLES_DIR, cls)\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "        print(\"Recording class: \", cls)\n",
    "        \n",
    "        for sample in range(SAMPLE_COUNT):\n",
    "            print(f\"Recording sample no.: {sample} / {SAMPLE_COUNT}\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            stream = p.open(format = FORMAT,\n",
    "                            channels = CHANNELS,\n",
    "                            rate = SAMPLE_RATE,\n",
    "                            input = True,\n",
    "                            frames_per_buffer = CHUNK,\n",
    "                            input_device_index = DEVICE_INDEX)\n",
    "            frames = []\n",
    "\n",
    "            for i in range(0, int(SAMPLE_RATE / CHUNK * DURATION)):\n",
    "                data = stream.read(CHUNK)\n",
    "                frames.append(np.frombuffer(data, dtype=np.int16))\n",
    "            \n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            \n",
    "            \"\"\"\n",
    "            #playback\n",
    "            print(\"Playback\")\n",
    "            \n",
    "            stream = p.open(format = FORMAT,\n",
    "                            channels = CHANNELS,\n",
    "                            rate = SAMPLE_RATE,\n",
    "                            output = True,\n",
    "                            frames_per_buffer = CHUNK)\n",
    "            \n",
    "            for frame in frames:\n",
    "                stream.write(frame)\n",
    "\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            \"\"\"\n",
    "\n",
    "            record = np.concatenate(frames, axis=0)\n",
    "            record = np.squeeze(record)\n",
    "            trimmed, index = librosa.effects.trim(record, top_db=15)\n",
    "\n",
    "\n",
    "            #record = librosa.util.normalize(record)\n",
    "\n",
    "            filename = os.path.join(dir, f\"{cls}_{sample}.wav\")\n",
    "            sf.write(filename, trimmed, SAMPLE_RATE)\n",
    "            print(\"Saved at: \", filename)\n",
    "            \n",
    "    p.terminate()\n",
    "    print(\"Finished recording.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Audio augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting every class to separate dict:\n",
    "class_counts = {}\n",
    "\n",
    "for dirpaths, dirnames, files in os.walk(SAMPLES_DIR):\n",
    "    for file in files:\n",
    "        #Load file\n",
    "        audio_file = os.path.join(dirpaths, file)\n",
    "        y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "        # Get class name and count\n",
    "        class_name = os.path.basename(dirpaths)\n",
    "        if class_name not in class_counts:\n",
    "            class_counts[class_name] = 0\n",
    "\n",
    "        new_dir = dirpaths.replace(SAMPLES_DIR, AUG_SAMPLES_DIR)\n",
    "        os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "        for i in range(NUM_AUGMENTED):\n",
    "            # Augment image\n",
    "            method = random.choice([\"pitch\", \"stretch\", \"noise\", \"db\"])\n",
    "\n",
    "            if method == \"pitch\":\n",
    "                steps = random.randint(-1, 1)  \n",
    "                augmented = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)\n",
    "\n",
    "            elif method == \"stretch\":\n",
    "                rate = random.uniform(0.9, 1.1)  # Random rate for time stretching\n",
    "                augmented = librosa.effects.time_stretch(y, rate=rate)\n",
    "\n",
    "            elif method == \"noise\":\n",
    "                noise = np.random.normal(0, 0.01, len(y))  # Gaussian noise\n",
    "                augmented = y + noise\n",
    "\n",
    "            elif method == \"db\":\n",
    "                audio_segment = AudioSegment.from_wav(audio_file)\n",
    "                db_change = random.randint(-10, 10)  # Random change in volume (dB)\n",
    "                augmented_segment = audio_segment + db_change\n",
    "                augmented = np.array(augmented_segment.get_array_of_samples())\n",
    "\n",
    "            class_counts[class_name] += 1\n",
    "            new_file = os.path.join(new_dir, f\"{file.split('_', 1)[0]}_{class_counts[class_name]}.wav\")\n",
    "            sf.write(new_file, augmented, SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def produce_metadata():\n",
    "    # Define the directory that contains your audio files\n",
    "    audio_dir = SAMPLES_DIR\n",
    "    metadata = {\n",
    "        \"filepath\": [],\n",
    "        \"label\": []\n",
    "    }\n",
    "\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(audio_dir)):\n",
    "        \n",
    "        if dirpath is not audio_dir:\n",
    "            label = dirpath.split(\"/\")[-1]\n",
    "            for f in filenames:\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                metadata[\"filepath\"].append(file_path)\n",
    "                metadata[\"label\"].append(label)\n",
    "        \n",
    "    df = pd.DataFrame(metadata)\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv('metadata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
