{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install tensorflow<2.11 tensorflow-gpu<2.11 tensorflow-io matplotlib==3.7.* librosa scikit-learn pandas numpy ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf \n",
    "from classify_utilities import AudioProcessor\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "import random\n",
    "from model import Deep_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define Paths to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = 'dataset'\n",
    "DATA_DIR = 'data'\n",
    "TEST_DIR = 'test'\n",
    "METADATA = \"metadata.csv\"\n",
    "MODEL_PATH = os.path.join(\"model\", \"model.keras\")\n",
    "LABELER_PATH = os.path.join(\"model\", \"label_encoder.joblib\")\n",
    "\n",
    "# create folders if they don't exist\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "if not os.path.exists('test'):\n",
    "    os.makedirs('test')\n",
    "if not os.path.exists('dataset'):\n",
    "    os.makedirs('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_CHUNK = 0.4 # seconds\n",
    "SLICE_AUDIO = False\n",
    "DATA_RANGE = 1.0\n",
    "\n",
    "NUM_CHANNELS = 1\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "N_FRAMES = None\n",
    "N_MELS = 256\n",
    "NFFT = 2048\n",
    "FMAX = SAMPLE_RATE // 2\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_processor = AudioProcessor(sample_rate=SAMPLE_RATE, \n",
    "                                 n_mels = N_MELS,\n",
    "                                 fmax = FMAX,\n",
    "                                 n_fft = NFFT,\n",
    "                                 hop_length = HOP_LENGTH, \n",
    "                                 audio_chunk = AUDIO_CHUNK,\n",
    "                                 slice_audio = SLICE_AUDIO,\n",
    "                                 data_range=DATA_RANGE\n",
    "                                 )\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = OneHotEncoder()\n",
    "\n",
    "classes = os.listdir(DATASET_DIR)\n",
    "classes.sort()\n",
    "classes = np.array(classes).reshape(-1, 1)\n",
    "\n",
    "try:\n",
    "    label_encoder.fit(classes)\n",
    "except IndexError:\n",
    "    print(\"No classes found in dataset folder\")\n",
    "\n",
    "# Serialize and save the fitted encoder\n",
    "joblib.dump(label_encoder, LABELER_PATH)\n",
    "\n",
    "def idx2label(idx):\n",
    "    idx_reshaped = np.array(idx).reshape(1, -1)\n",
    "    return label_encoder.inverse_transform(idx_reshaped)[0][0]\n",
    "\n",
    "def label2idx(label):\n",
    "    label = np.array(label).reshape(-1, 1)\n",
    "    return label_encoder.transform(label).toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_label = random.choice(os.listdir(DATASET_DIR))\n",
    "label2idx(random_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label(label2idx(random_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External labeler\n",
    "audio_processor.idx2label(label2idx(random_label), joblib.load(LABELER_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset:\n",
    "# List all the files in dictionare and subdictionaries.\n",
    "metadata = []\n",
    "\n",
    "for root, _, files in os.walk(DATASET_DIR):\n",
    "    for i, file in enumerate(files):\n",
    "        if file.endswith('.wav'):\n",
    "            filename = os.path.join(root, file)\n",
    "            label = os.path.basename(root)\n",
    "            class_ = label2idx(label)\n",
    "            num_channels, sample_rate, bit_depth, avg_rms, length_in_seconds, length_in_frames = audio_processor.read_file_properties(filename)\n",
    "            metadata.append({\n",
    "                'filename': filename, \n",
    "                'label': label, \n",
    "                'class': class_,\n",
    "                'num_channels': num_channels, \n",
    "                'sample_rate': sample_rate, \n",
    "                'bit_depth': bit_depth, \n",
    "                'avg_rms': avg_rms, \n",
    "                'length_in_seconds': length_in_seconds, \n",
    "                'length_in_frames': length_in_frames\n",
    "            })\n",
    "\n",
    "            print(f\"Processing label: {label}, {i}th file named: {file}\")\n",
    "        else:\n",
    "            print(f\"Skipped {i} file. {file}\")\n",
    "            \n",
    "metadata = pd.DataFrame(metadata)\n",
    "metadata.to_csv(METADATA, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot class waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = metadata[\"label\"].unique()\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i, label in enumerate(labels):\n",
    "    filtered_df = metadata[metadata[\"label\"] == label]\n",
    "    slice_file_name = filtered_df[\"filename\"].iloc[0]\n",
    "    fold = filtered_df[\"label\"].iloc[0]\n",
    "    fig.add_subplot(5, 2, i+1)\n",
    "    plt.title(label)\n",
    "    data, sr = librosa.load(os.path.join(slice_file_name), sr=SAMPLE_RATE, mono=False)\n",
    "    librosa.display.waveshow(y = data, sr=sr, color=\"r\", alpha=0.5, label='Harmonic')\n",
    "    print(slice_file_name)\n",
    "     \n",
    "plt.tight_layout()  # This will adjust spacing between subplots to prevent overlap\n",
    "plt.show()  # This will display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of channels \n",
    "print(\"Channels: \")\n",
    "print(metadata.num_channels.value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "# sample rates \n",
    "print(\"Sample Rates: \")\n",
    "print(metadata.sample_rate.value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "# bit depth\n",
    "print(\"Bit Depth: \")\n",
    "print(metadata.bit_depth.value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "# length in samples\n",
    "print(\"Samples: \")\n",
    "print(metadata.length_in_frames.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# length in seconds\n",
    "print(\"Length (s): \")\n",
    "print(metadata.length_in_seconds.describe())\n",
    "\n",
    "# RMS\n",
    "print(metadata.avg_rms.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Audio Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test audio preprocessing methods\n",
    "-   Librosa -> \n",
    "        SR: 22050\n",
    "        channel: 1\n",
    "    trim/pad ->\n",
    "        length: 3s (3x22050)\n",
    "    spectrogram ->\n",
    "        mel-spectrogram / spectrogram / MFCC\n",
    "    post-process ->\n",
    "        to Db (log scale, more apparent patterns)\n",
    "        abs \n",
    "    normalize ->\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Fourier transform\n",
    "#In each iteration of the loop, the variable index is assigned the index value of the current row, and the variable row is assigned the data of the current row (as a Series object).\n",
    "rows = metadata.iloc[[34, 1280]]\n",
    "\n",
    "#rows = metadata.sample(2)\n",
    "slice_length = AUDIO_CHUNK\n",
    "samples_show = len(rows)\n",
    "pass_ = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows=samples_show, ncols=2, figsize=(12, samples_show* 5))\n",
    "\n",
    "for i, row in rows.iterrows():    \n",
    "    if pass_ > samples_show:\n",
    "        break\n",
    "    audio_file, librosa_sample_rate = librosa.load(row[\"filename\"], sr=SAMPLE_RATE)\n",
    "    if SLICE_AUDIO: \n",
    "        print(slice)\n",
    "        sample_length = slice_length * librosa_sample_rate\n",
    "\n",
    "        audio_file = audio_file[:sample_length]\n",
    "        if len(audio_file) < sample_length:\n",
    "            audio_file = np.pad(audio_file, (0, sample_length - len(audio_file)), constant_values=0)\n",
    "\n",
    "    #spectrogram = audio_processor(data = audio_file)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio_file, sr=librosa_sample_rate, n_mels=256, fmax = FMAX, n_fft=2048, hop_length=512)\n",
    "    spectrogram = (librosa.power_to_db(spectrogram, ref=np.max))\n",
    "\n",
    "    # general scale normalization with min-max\n",
    "    #min_db, max_db = -60, 80\n",
    "    #spectrogram = np.clip((spectrogram - min_db) / (max_db - min_db), 0, 1)\n",
    "    #spectrogram = (spectrogram - min_db) / (max_db - min_db)\n",
    "\n",
    "    # Min-Max normalization\n",
    "    spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min())\n",
    "\n",
    "        # wave Plot\n",
    "    axes[pass_, 0].set_title(f\"Label: {row['label']} Waveform\")\n",
    "    librosa.display.waveshow(audio_file, sr=librosa_sample_rate, ax=axes[pass_, 0])\n",
    "    # spectrogram plot\n",
    "    axes[pass_, 1].set_title(f\"Label: {row['label']} Spectrogram\")\n",
    "    img = librosa.display.specshow(spectrogram, sr=librosa_sample_rate, x_axis='time', y_axis='mel', ax=axes[pass_, 1])\n",
    "    pass_ += 1\n",
    "\n",
    "\n",
    "print(f\"audio_file shape {audio_file.shape} - (frames, channels)\")\n",
    "print(f\"audio_file sample rate {librosa_sample_rate} Hz\")\n",
    "print(f\"Spectrogram shape {spectrogram.shape} - (mels/frequency, frames/time)\")\n",
    "print(f\"spectrogram min: {spectrogram.min()} spectrogram max: {spectrogram.max()}, average: {spectrogram.mean()}\")\n",
    "print(f\"spectrogram dtype: {spectrogram.dtype}\")\n",
    "print(f\"audio dtype: {audio_file.dtype} - bit depth\")\n",
    "\n",
    "#fig.colorbar(img, ax=axes[:, 0], format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Extract features and labels into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "\n",
    "def extract_features(row):\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    \n",
    "    audio_file,_ = librosa.load(row[\"filename\"], sr=SAMPLE_RATE)\n",
    "\n",
    "    spectrogram = audio_processor(\n",
    "        data = audio_file, data_range = 255) # 1 or 255 range\n",
    "    \n",
    "    shape = spectrogram.shape\n",
    "\n",
    "    return spectrogram, class_label, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In each iteration of the loop, the variable index is assigned the index value of the current row, and the variable row is assigned the data of the current row (as a Series object).\n",
    "features = []\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    features.append(extract_features(row))\n",
    "    print(f\"Processed {index} file. {row['filename']}\")\n",
    "\n",
    "   \n",
    "dataset_df = pd.DataFrame(features, columns=[\"features\", \"class_label\", \"shape\"])\n",
    "print('Finished feature extraction from ', len(dataset_df), ' files') \n",
    "N_FRAMES = dataset_df[\"shape\"].iloc[0][0]\n",
    "print(f\"Number of frames: {N_FRAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our feature data stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {dataset_df['shape'].value_counts()}\")\n",
    "print(f\"Data values Min: {dataset_df['features'].apply(lambda x: x.min()).min()}, Max: {dataset_df['features'].apply(lambda x: x.max()).max()}, dtype: {dataset_df['features'].apply(lambda x: x.dtype).unique()} \\nAverage: {dataset_df['features'].apply(lambda x: x.mean()).mean()}, Median: {dataset_df['features'].apply(lambda x: x.mean()).median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset_df.features.tolist())\n",
    "y = np.array(dataset_df.class_label.tolist())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"randomm feature example: {X[0]} and label: {y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = dataset_df.sample(n=4)\n",
    "\n",
    "# Create subplots with 2 rows and 2 columns\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Iterate over the subplots and fill each with a spectrogram\n",
    "for i, (idx, row) in enumerate(selected_rows.iterrows()):\n",
    "    spectrogram = row['features']\n",
    "    label = row['class_label']\n",
    "    ax = axs[i // 2, i % 2]  # Calculate the subplot position\n",
    "    im = ax.imshow(spectrogram, aspect='auto', origin='lower', cmap='viridis',\n",
    "                   extent=[0, spectrogram.shape[1] / SAMPLE_RATE, 0, SAMPLE_RATE / 2])\n",
    "    ax.set_title(f'Spectrogram {i+1} - Label: {idx2label(label)}')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    fig.colorbar(im, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the random feature array\n",
    "sample_no = 42\n",
    "sample_f = dataset_df.iloc[sample_no][\"features\"]\n",
    "sample_l = dataset_df.iloc[sample_no][\"class_label\"]\n",
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(sample_f, sr=SAMPLE_RATE, x_axis='mel', y_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogram label: ' + idx2label(sample_l))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Reshape sets for NN input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], N_FRAMES, N_MELS, NUM_CHANNELS)\n",
    "x_test = x_test.reshape(x_test.shape[0], N_FRAMES, N_MELS, NUM_CHANNELS)\n",
    "\n",
    "num_labels = y.shape[1]\n",
    "print(f\"num_labels: {num_labels}\")\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Load deep neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load a class with various model archietectures to test\n",
    "modelClass = Deep_NN(num_classes=num_labels, dim1 = N_FRAMES, dim2 = N_MELS, dim3 = NUM_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model architecture to train on\n",
    "#model = modelClass.defaultCNN()\n",
    "#model = modelClass.customCNN1()\n",
    "\n",
    "#model = modelClass.mobilenetv3_nn() \n",
    "model = modelClass.convnext_nn(\"tiny\")\n",
    "#model = modelClass.effnetv2_nn()\n",
    "#model = modelClass.dense_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Compile Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='CategoricalCrossentropy', \n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Fit Model, View Loss and KPI Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 epochs=EPOCHS, \n",
    "                 validation_data=(x_test, y_test), \n",
    "                 batch_size=BATCH_SIZE\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(hist.history['accuracy'], 'r')\n",
    "plt.plot(hist.history['val_accuracy'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Make a Prediction on a Single Clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Make a Prediction, Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(idx2label(predictions[19]))\n",
    "print(idx2label(y_test[19]))\n",
    "print(f\"input default shape: {x_test[1].shape}\")\n",
    "print(f\"reshaped input feature shape: {np.expand_dims((x_test[21]), axis=0).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(np.expand_dims((x_test[1]), axis=0))\n",
    "print(prediction)\n",
    "print(idx2label(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=1)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'predictions' is an array of predicted probabilities for each class\n",
    "# And 'y_test' is an array of actual class labels\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "predicted_labels = [idx2label(pred) for pred in predictions]\n",
    "y_test_labels = [idx2label(pred) for pred in y_test]\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, predicted_labels)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "plt.title(f\"Confusion Matrix (Accuracy: {score[1]})\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Load local model and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encoder in the inference environment\n",
    "loaded_encoder = joblib.load(LABELER_PATH)\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Inference on loacl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = os.listdir(TEST_DIR)\n",
    "random.shuffle(audio_files)\n",
    "\n",
    "try:\n",
    "    print(audio_files[1])\n",
    "    audio_labels = [os.path.splitext(file)[0] for file in audio_files]\n",
    "except IndexError:\n",
    "    print(\"No files in test directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in audio_files:\n",
    "    path = os.path.join(TEST_DIR, file)\n",
    "    print(path)\n",
    "    data, _ = librosa.load(path, sr=SAMPLE_RATE)\n",
    "    prediction_feature = audio_processor(\n",
    "            data = data\n",
    "        )\n",
    "    \n",
    "    # Reshape to match model input shape\n",
    "    prediction_feature = prediction_feature.reshape(1, N_FRAMES, N_MELS, NUM_CHANNELS)\n",
    "    predicted_class = idx2label(model.predict(prediction_feature)) \n",
    "    print(\"The predicted class is:\", predicted_class, '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run \"run.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_class import SoundClassificationService\n",
    "\n",
    "def main():\n",
    "\n",
    "    config = {\n",
    "        \"model_path\": MODEL_PATH,\n",
    "        \"labels_path\": LABELER_PATH,\n",
    "        \n",
    "        \"sample_rate\": SAMPLE_RATE,\n",
    "        \"num_channels\": NUM_CHANNELS,\n",
    "        \"audio_chunk\": AUDIO_CHUNK,\n",
    "        \n",
    "        \"num_mels\": N_MELS,\n",
    "        \"n_fft\": NFFT,\n",
    "        \"fmax\": FMAX,\n",
    "        \"hop_length\": HOP_LENGTH,\n",
    "        \n",
    "        \"confidence_threshold\": 0.5,\n",
    "        \"listening_hop_length\": 0.6,\n",
    "        \"device\": \"cpu\"\n",
    "\n",
    "    }\n",
    "\n",
    "    service = SoundClassificationService.get_instance(config)\n",
    "    service.listen_and_predict(duration=AUDIO_CHUNK, overlap=0.5)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
