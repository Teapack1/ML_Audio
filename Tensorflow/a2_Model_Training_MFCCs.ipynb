{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 63\n",
    "num_channels = 1\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the Model**\n",
    "<p>Loss function - we will use categorical_crossentropy. This is the most common choice for classification. A lower score indicates that the model is performing better.</p>\n",
    "<p>Metrics - we will use the accuracy metric which will allow us to view the accuracy score on the validation data when we train the model.</p>\n",
    "<p>Optimizer - here we will use adam which is a generally good optimizer for many use cases.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 39, 62, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 19, 31, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 19, 31, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 30, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 15, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9, 15, 32)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 14, 64)         8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 6, 128)         32896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 3, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "55/55 [==============================] - 2s 7ms/step - loss: 15.9572 - accuracy: 0.0424\n",
      "Pre-training accuracy: 4.2358%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 2.5636 - accuracy: 0.3185\n",
      "Epoch 1: val_loss improved from inf to 1.56936, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 7s 27ms/step - loss: 2.5636 - accuracy: 0.3185 - val_loss: 1.5694 - val_accuracy: 0.4665\n",
      "Epoch 2/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.4284 - accuracy: 0.4924\n",
      "Epoch 2: val_loss improved from 1.56936 to 1.34589, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 1.4290 - accuracy: 0.4921 - val_loss: 1.3459 - val_accuracy: 0.5621\n",
      "Epoch 3/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.2477 - accuracy: 0.5596\n",
      "Epoch 3: val_loss improved from 1.34589 to 1.21468, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 1.2477 - accuracy: 0.5596 - val_loss: 1.2147 - val_accuracy: 0.6056\n",
      "Epoch 4/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.1409 - accuracy: 0.6020\n",
      "Epoch 4: val_loss improved from 1.21468 to 1.12248, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 1.1402 - accuracy: 0.6020 - val_loss: 1.1225 - val_accuracy: 0.6411\n",
      "Epoch 5/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.0336 - accuracy: 0.6458\n",
      "Epoch 5: val_loss improved from 1.12248 to 1.07650, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 1.0336 - accuracy: 0.6458 - val_loss: 1.0765 - val_accuracy: 0.6571\n",
      "Epoch 6/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9643 - accuracy: 0.6674\n",
      "Epoch 6: val_loss improved from 1.07650 to 0.94161, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.9648 - accuracy: 0.6673 - val_loss: 0.9416 - val_accuracy: 0.6817\n",
      "Epoch 7/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8915 - accuracy: 0.6955\n",
      "Epoch 7: val_loss improved from 0.94161 to 0.87230, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.8915 - accuracy: 0.6955 - val_loss: 0.8723 - val_accuracy: 0.7224\n",
      "Epoch 8/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8542 - accuracy: 0.7069\n",
      "Epoch 8: val_loss improved from 0.87230 to 0.83875, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.8551 - accuracy: 0.7065 - val_loss: 0.8388 - val_accuracy: 0.7310\n",
      "Epoch 9/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8138 - accuracy: 0.7251\n",
      "Epoch 9: val_loss improved from 0.83875 to 0.76454, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.8153 - accuracy: 0.7247 - val_loss: 0.7645 - val_accuracy: 0.7539\n",
      "Epoch 10/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7653 - accuracy: 0.7403\n",
      "Epoch 10: val_loss did not improve from 0.76454\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.7656 - accuracy: 0.7400 - val_loss: 0.7869 - val_accuracy: 0.7447\n",
      "Epoch 11/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7300 - accuracy: 0.7504\n",
      "Epoch 11: val_loss improved from 0.76454 to 0.72358, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.7288 - accuracy: 0.7509 - val_loss: 0.7236 - val_accuracy: 0.7779\n",
      "Epoch 12/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7011 - accuracy: 0.7575\n",
      "Epoch 12: val_loss improved from 0.72358 to 0.72006, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.7010 - accuracy: 0.7578 - val_loss: 0.7201 - val_accuracy: 0.7642\n",
      "Epoch 13/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.7742\n",
      "Epoch 13: val_loss improved from 0.72006 to 0.68353, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.6731 - accuracy: 0.7742 - val_loss: 0.6835 - val_accuracy: 0.7808\n",
      "Epoch 14/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.6310 - accuracy: 0.7843\n",
      "Epoch 14: val_loss improved from 0.68353 to 0.62241, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.6310 - accuracy: 0.7843 - val_loss: 0.6224 - val_accuracy: 0.7905\n",
      "Epoch 15/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.6098 - accuracy: 0.7933\n",
      "Epoch 15: val_loss improved from 0.62241 to 0.61555, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.6096 - accuracy: 0.7933 - val_loss: 0.6156 - val_accuracy: 0.7974\n",
      "Epoch 16/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.5953 - accuracy: 0.7981\n",
      "Epoch 16: val_loss improved from 0.61555 to 0.61014, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.5949 - accuracy: 0.7983 - val_loss: 0.6101 - val_accuracy: 0.8117\n",
      "Epoch 17/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.5809 - accuracy: 0.7997\n",
      "Epoch 17: val_loss improved from 0.61014 to 0.58809, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.5805 - accuracy: 0.7999 - val_loss: 0.5881 - val_accuracy: 0.8031\n",
      "Epoch 18/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8106\n",
      "Epoch 18: val_loss improved from 0.58809 to 0.56818, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.5495 - accuracy: 0.8106 - val_loss: 0.5682 - val_accuracy: 0.8248\n",
      "Epoch 19/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.5269 - accuracy: 0.8197\n",
      "Epoch 19: val_loss did not improve from 0.56818\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.5249 - accuracy: 0.8203 - val_loss: 0.5784 - val_accuracy: 0.8117\n",
      "Epoch 20/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.8311\n",
      "Epoch 20: val_loss improved from 0.56818 to 0.53531, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.5059 - accuracy: 0.8311 - val_loss: 0.5353 - val_accuracy: 0.8277\n",
      "Epoch 21/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.4996 - accuracy: 0.8232\n",
      "Epoch 21: val_loss improved from 0.53531 to 0.50815, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4983 - accuracy: 0.8236 - val_loss: 0.5081 - val_accuracy: 0.8392\n",
      "Epoch 22/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.4950 - accuracy: 0.8314\n",
      "Epoch 22: val_loss did not improve from 0.50815\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4945 - accuracy: 0.8316 - val_loss: 0.5100 - val_accuracy: 0.8369\n",
      "Epoch 23/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.4633 - accuracy: 0.8412\n",
      "Epoch 23: val_loss improved from 0.50815 to 0.50622, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4629 - accuracy: 0.8412 - val_loss: 0.5062 - val_accuracy: 0.8363\n",
      "Epoch 24/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.4480 - accuracy: 0.8478\n",
      "Epoch 24: val_loss improved from 0.50622 to 0.47121, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4482 - accuracy: 0.8478 - val_loss: 0.4712 - val_accuracy: 0.8443\n",
      "Epoch 25/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.8503\n",
      "Epoch 25: val_loss did not improve from 0.47121\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4412 - accuracy: 0.8504 - val_loss: 0.4931 - val_accuracy: 0.8283\n",
      "Epoch 26/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.8460\n",
      "Epoch 26: val_loss did not improve from 0.47121\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4448 - accuracy: 0.8460 - val_loss: 0.4909 - val_accuracy: 0.8363\n",
      "Epoch 27/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.8496\n",
      "Epoch 27: val_loss did not improve from 0.47121\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4379 - accuracy: 0.8497 - val_loss: 0.5084 - val_accuracy: 0.8351\n",
      "Epoch 28/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.8538\n",
      "Epoch 28: val_loss improved from 0.47121 to 0.44314, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4147 - accuracy: 0.8538 - val_loss: 0.4431 - val_accuracy: 0.8632\n",
      "Epoch 29/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.3971 - accuracy: 0.8640\n",
      "Epoch 29: val_loss did not improve from 0.44314\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.3971 - accuracy: 0.8639 - val_loss: 0.4791 - val_accuracy: 0.8432\n",
      "Epoch 30/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.4014 - accuracy: 0.8591\n",
      "Epoch 30: val_loss did not improve from 0.44314\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.4014 - accuracy: 0.8591 - val_loss: 0.4536 - val_accuracy: 0.8558\n",
      "Epoch 31/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.3986 - accuracy: 0.8620\n",
      "Epoch 31: val_loss did not improve from 0.44314\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.3983 - accuracy: 0.8621 - val_loss: 0.4722 - val_accuracy: 0.8420\n",
      "Epoch 32/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8651\n",
      "Epoch 32: val_loss improved from 0.44314 to 0.43671, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.3779 - accuracy: 0.8653 - val_loss: 0.4367 - val_accuracy: 0.8701\n",
      "Epoch 33/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.3654 - accuracy: 0.8733\n",
      "Epoch 33: val_loss did not improve from 0.43671\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.3650 - accuracy: 0.8734 - val_loss: 0.4533 - val_accuracy: 0.8592\n",
      "Epoch 34/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.3685 - accuracy: 0.8700\n",
      "Epoch 34: val_loss did not improve from 0.43671\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.3683 - accuracy: 0.8702 - val_loss: 0.4734 - val_accuracy: 0.8403\n",
      "Epoch 35/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.3623 - accuracy: 0.8754\n",
      "Epoch 35: val_loss did not improve from 0.43671\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.3613 - accuracy: 0.8759 - val_loss: 0.4371 - val_accuracy: 0.8546\n",
      "Epoch 36/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.3574 - accuracy: 0.8780\n",
      "Epoch 36: val_loss improved from 0.43671 to 0.39970, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.3577 - accuracy: 0.8780 - val_loss: 0.3997 - val_accuracy: 0.8764\n",
      "Epoch 37/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.8815\n",
      "Epoch 37: val_loss did not improve from 0.39970\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.3426 - accuracy: 0.8815 - val_loss: 0.4609 - val_accuracy: 0.8540\n",
      "Epoch 38/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8783\n",
      "Epoch 38: val_loss improved from 0.39970 to 0.39956, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.3446 - accuracy: 0.8779 - val_loss: 0.3996 - val_accuracy: 0.8678\n",
      "Epoch 39/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.8825\n",
      "Epoch 39: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.3375 - accuracy: 0.8825 - val_loss: 0.4543 - val_accuracy: 0.8523\n",
      "Epoch 40/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.3204 - accuracy: 0.8898\n",
      "Epoch 40: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.3202 - accuracy: 0.8898 - val_loss: 0.4384 - val_accuracy: 0.8558\n",
      "Epoch 41/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.8836\n",
      "Epoch 41: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.3333 - accuracy: 0.8835 - val_loss: 0.4525 - val_accuracy: 0.8580\n",
      "Epoch 42/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.3033 - accuracy: 0.8926\n",
      "Epoch 42: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.3033 - accuracy: 0.8926 - val_loss: 0.4606 - val_accuracy: 0.8575\n",
      "Epoch 43/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.3146 - accuracy: 0.8884\n",
      "Epoch 43: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.3145 - accuracy: 0.8888 - val_loss: 0.4106 - val_accuracy: 0.8683\n",
      "Epoch 44/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.8908\n",
      "Epoch 44: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.3105 - accuracy: 0.8911 - val_loss: 0.4154 - val_accuracy: 0.8666\n",
      "Epoch 45/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.8896\n",
      "Epoch 45: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.3174 - accuracy: 0.8896 - val_loss: 0.4139 - val_accuracy: 0.8701\n",
      "Epoch 46/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.8952\n",
      "Epoch 46: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.2973 - accuracy: 0.8949 - val_loss: 0.4605 - val_accuracy: 0.8569\n",
      "Epoch 47/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.8912\n",
      "Epoch 47: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.3094 - accuracy: 0.8913 - val_loss: 0.4212 - val_accuracy: 0.8661\n",
      "Epoch 48/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2964 - accuracy: 0.8962\n",
      "Epoch 48: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.2964 - accuracy: 0.8962 - val_loss: 0.4184 - val_accuracy: 0.8706\n",
      "Epoch 49/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2849 - accuracy: 0.8982\n",
      "Epoch 49: val_loss did not improve from 0.39956\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2845 - accuracy: 0.8984 - val_loss: 0.4051 - val_accuracy: 0.8764\n",
      "Epoch 50/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.9015\n",
      "Epoch 50: val_loss improved from 0.39956 to 0.38352, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2961 - accuracy: 0.9015 - val_loss: 0.3835 - val_accuracy: 0.8821\n",
      "Epoch 51/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.9009\n",
      "Epoch 51: val_loss improved from 0.38352 to 0.37469, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.2684 - accuracy: 0.9011 - val_loss: 0.3747 - val_accuracy: 0.8844\n",
      "Epoch 52/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.9016\n",
      "Epoch 52: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2752 - accuracy: 0.9016 - val_loss: 0.4047 - val_accuracy: 0.8695\n",
      "Epoch 53/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2821 - accuracy: 0.9026\n",
      "Epoch 53: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2816 - accuracy: 0.9028 - val_loss: 0.3858 - val_accuracy: 0.8832\n",
      "Epoch 54/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2765 - accuracy: 0.9025\n",
      "Epoch 54: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2769 - accuracy: 0.9024 - val_loss: 0.3871 - val_accuracy: 0.8815\n",
      "Epoch 55/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.9051\n",
      "Epoch 55: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2612 - accuracy: 0.9049 - val_loss: 0.3893 - val_accuracy: 0.8775\n",
      "Epoch 56/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9060\n",
      "Epoch 56: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.2710 - accuracy: 0.9061 - val_loss: 0.4443 - val_accuracy: 0.8620\n",
      "Epoch 57/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2727 - accuracy: 0.9041\n",
      "Epoch 57: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2725 - accuracy: 0.9041 - val_loss: 0.4076 - val_accuracy: 0.8672\n",
      "Epoch 58/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.9100\n",
      "Epoch 58: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2599 - accuracy: 0.9104 - val_loss: 0.3932 - val_accuracy: 0.8827\n",
      "Epoch 59/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.9077\n",
      "Epoch 59: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2619 - accuracy: 0.9072 - val_loss: 0.3799 - val_accuracy: 0.8786\n",
      "Epoch 60/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2563 - accuracy: 0.9080\n",
      "Epoch 60: val_loss did not improve from 0.37469\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2568 - accuracy: 0.9078 - val_loss: 0.4153 - val_accuracy: 0.8735\n",
      "Epoch 61/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9115\n",
      "Epoch 61: val_loss improved from 0.37469 to 0.37143, saving model to saved_models\\mfcc_weights.best.basic_cnn.hdf5\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2571 - accuracy: 0.9115 - val_loss: 0.3714 - val_accuracy: 0.8781\n",
      "Epoch 62/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.9087\n",
      "Epoch 62: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 0.2554 - accuracy: 0.9089 - val_loss: 0.4019 - val_accuracy: 0.8724\n",
      "Epoch 63/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9146\n",
      "Epoch 63: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.2365 - accuracy: 0.9147 - val_loss: 0.3804 - val_accuracy: 0.8706\n",
      "Epoch 64/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9117\n",
      "Epoch 64: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.2505 - accuracy: 0.9118 - val_loss: 0.4190 - val_accuracy: 0.8666\n",
      "Epoch 65/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2363 - accuracy: 0.9146\n",
      "Epoch 65: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.2365 - accuracy: 0.9144 - val_loss: 0.4258 - val_accuracy: 0.8615\n",
      "Epoch 66/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9104\n",
      "Epoch 66: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.2465 - accuracy: 0.9104 - val_loss: 0.4125 - val_accuracy: 0.8672\n",
      "Epoch 67/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2318 - accuracy: 0.9171\n",
      "Epoch 67: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 0.2319 - accuracy: 0.9170 - val_loss: 0.4262 - val_accuracy: 0.8729\n",
      "Epoch 68/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2279 - accuracy: 0.9204\n",
      "Epoch 68: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.2277 - accuracy: 0.9205 - val_loss: 0.4321 - val_accuracy: 0.8752\n",
      "Epoch 69/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2349 - accuracy: 0.9152\n",
      "Epoch 69: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.2349 - accuracy: 0.9148 - val_loss: 0.4003 - val_accuracy: 0.8804\n",
      "Epoch 70/72\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9183\n",
      "Epoch 70: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2282 - accuracy: 0.9183 - val_loss: 0.4315 - val_accuracy: 0.8655\n",
      "Epoch 71/72\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.2440 - accuracy: 0.9167\n",
      "Epoch 71: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.2443 - accuracy: 0.9165 - val_loss: 0.4192 - val_accuracy: 0.8746\n",
      "Epoch 72/72\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9182\n",
      "Epoch 72: val_loss did not improve from 0.37143\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.2203 - accuracy: 0.9181 - val_loss: 0.4331 - val_accuracy: 0.8746\n",
      "Training completed in time:  0:06:38.522914\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 72\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/mfcc_weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.970365047454834\n",
      "Testing Accuracy:  0.8746422529220581\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/MFCC_Classification_Model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice for common length of 1 seconds\n",
    "def slice_audio(librosa_audio, librosa_sample_rate = SAMPLE_RATE):\n",
    "    SAMPLE_LENGTH = 2 * librosa_sample_rate\n",
    "\n",
    "    librosa_audio_sliced = librosa_audio[:SAMPLE_LENGTH]\n",
    "    if len(librosa_audio) < SAMPLE_LENGTH:\n",
    "        # print(f\"Audio length {len(librosa_audio)} is less than 2 seconds. Padding with zeros.\")\n",
    "        # np.pad specifies the number of values to add at the beginning and the end of the librosa_audio array.\n",
    "        # 0 -> no padding in the beginning.\n",
    "        # SAMPLE_LENGTH - len(librosa_audio) -> number of zeros to end, ensuring the total length is 2 seconds.\n",
    "        librosa_audio_sliced = np.pad(librosa_audio, (0, SAMPLE_LENGTH - len(librosa_audio)), constant_values=0)\n",
    "    return librosa_audio_sliced\n",
    "\n",
    "# print(f\"Librosa audio before: {librosa_audio.shape} and after: {slice_audio(librosa_audio).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_mfccs(audio_path):\n",
    "    audio_file, librosa_sample_rate = librosa.load(audio_path, sr=SAMPLE_RATE, res_type='kaiser_fast')\n",
    "    audio_file = slice_audio(audio_file, librosa_sample_rate)\n",
    "    mfccs = librosa.feature.mfcc(y=audio_file, sr=SAMPLE_RATE, n_mfcc=40)\n",
    "\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_mfccs(file_name)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = np.argmax(model.predict(prediction_feature), axis=-1)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**\n",
    "<p>On new samples<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('saved_models/MFCC_Classification_Model.keras')\n",
    "\n",
    "VAL_DIR = \"D:\\\\Code\\\\ProjectsPython\\\\ML_TrainingGround\\\\ML_Audio\\\\data\\\\UrbanSound8K\\\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n",
      "The predicted class is: jackhammer \n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "air_conditioner \t\t :  0.24512082338333129882812500000000\n",
      "car_horn \t\t :  0.00003541887053870595991611480713\n",
      "children_playing \t\t :  0.00031827684142626821994781494141\n",
      "dog_bark \t\t :  0.00039201395702548325061798095703\n",
      "drilling \t\t :  0.00069823028752580285072326660156\n",
      "engine_idling \t\t :  0.03670024871826171875000000000000\n",
      "gun_shot \t\t :  0.00001047563091560732573270797729\n",
      "jackhammer \t\t :  0.71592324972152709960937500000000\n",
      "siren \t\t :  0.00001376378622808260843157768250\n",
      "street_music \t\t :  0.00078757031587883830070495605469\n"
     ]
    }
   ],
   "source": [
    "# Class: Air Conditioner\n",
    "filename = os.path.join(VAL_DIR, \"air_conditioner.mp3\")\n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "The predicted class is: engine_idling \n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "air_conditioner \t\t :  0.00286324089393019676208496093750\n",
      "car_horn \t\t :  0.00130091654136776924133300781250\n",
      "children_playing \t\t :  0.01832863874733448028564453125000\n",
      "dog_bark \t\t :  0.00916135776787996292114257812500\n",
      "drilling \t\t :  0.00254237023182213306427001953125\n",
      "engine_idling \t\t :  0.96144711971282958984375000000000\n",
      "gun_shot \t\t :  0.00018570467364042997360229492188\n",
      "jackhammer \t\t :  0.00011460556561360135674476623535\n",
      "siren \t\t :  0.00045504764420911669731140136719\n",
      "street_music \t\t :  0.00360105535946786403656005859375\n"
     ]
    }
   ],
   "source": [
    "# Class: Car idle\n",
    "filename = os.path.join(VAL_DIR, \"car_idle.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "The predicted class is: dog_bark \n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "air_conditioner \t\t :  0.00000012250313830008963122963905\n",
      "car_horn \t\t :  0.00000000019495487169063352439480\n",
      "children_playing \t\t :  0.00010973527241731062531471252441\n",
      "dog_bark \t\t :  0.99856144189834594726562500000000\n",
      "drilling \t\t :  0.00002193625732616055756807327271\n",
      "engine_idling \t\t :  0.00000723267748981015756726264954\n",
      "gun_shot \t\t :  0.00000198247585103672463446855545\n",
      "jackhammer \t\t :  0.00000000284088241819802078680368\n",
      "siren \t\t :  0.00000902459214557893574237823486\n",
      "street_music \t\t :  0.00128845463041216135025024414062\n"
     ]
    }
   ],
   "source": [
    "# Class: dog bark\n",
    "filename = os.path.join(VAL_DIR, \"dog_barking.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "The predicted class is: drilling \n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "air_conditioner \t\t :  0.00000003343551924217535997740924\n",
      "car_horn \t\t :  0.00000099133046660426771268248558\n",
      "children_playing \t\t :  0.00000083997070987607003189623356\n",
      "dog_bark \t\t :  0.00000586846954320208169519901276\n",
      "drilling \t\t :  0.99572229385375976562500000000000\n",
      "engine_idling \t\t :  0.00000006921179362961993319913745\n",
      "gun_shot \t\t :  0.00000000029437630111317503178725\n",
      "jackhammer \t\t :  0.00424809427931904792785644531250\n",
      "siren \t\t :  0.00000003137820669962820829823613\n",
      "street_music \t\t :  0.00002177190617658197879791259766\n"
     ]
    }
   ],
   "source": [
    "# Class: drill\n",
    "filename = os.path.join(VAL_DIR, \"drill.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "The predicted class is: drilling \n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "air_conditioner \t\t :  0.00000009252584476371339405886829\n",
      "car_horn \t\t :  0.01980255171656608581542968750000\n",
      "children_playing \t\t :  0.00029384542722254991531372070312\n",
      "dog_bark \t\t :  0.00001114642145694233477115631104\n",
      "drilling \t\t :  0.89985805749893188476562500000000\n",
      "engine_idling \t\t :  0.00000005315106577086226025130600\n",
      "gun_shot \t\t :  0.00000000738547267786771044484340\n",
      "jackhammer \t\t :  0.08002285659313201904296875000000\n",
      "siren \t\t :  0.00000501551585330162197351455688\n",
      "street_music \t\t :  0.00000646574881102424114942550659\n"
     ]
    }
   ],
   "source": [
    "# Class: jackhammer\n",
    "filename = os.path.join(VAL_DIR, \"jackhammer.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "The predicted class is: children_playing \n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "air_conditioner \t\t :  0.00000000000004040043242981537774\n",
      "car_horn \t\t :  0.00000000000601772451314097622799\n",
      "children_playing \t\t :  0.99999940395355224609375000000000\n",
      "dog_bark \t\t :  0.00000003114811519822069385554641\n",
      "drilling \t\t :  0.00000000000016285878082309551695\n",
      "engine_idling \t\t :  0.00000000000001992895221948360468\n",
      "gun_shot \t\t :  0.00000000000096059521014629778435\n",
      "jackhammer \t\t :  0.00000000000000000007123822253209\n",
      "siren \t\t :  0.00000030755370516999391838908195\n",
      "street_music \t\t :  0.00000032211161737905058544129133\n"
     ]
    }
   ],
   "source": [
    "# Class: kids playing\n",
    "filename = os.path.join(VAL_DIR, \"kids_playing.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "The predicted class is: siren \n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "air_conditioner \t\t :  0.00000000000000000000000001140671\n",
      "car_horn \t\t :  0.00000000000000002112585039183073\n",
      "children_playing \t\t :  0.00000001112683900572619677404873\n",
      "dog_bark \t\t :  0.00000003421703453909685777034611\n",
      "drilling \t\t :  0.00000000309306646961715614452260\n",
      "engine_idling \t\t :  0.00000000000000000280541034443381\n",
      "gun_shot \t\t :  0.00000000000000000000000000131681\n",
      "jackhammer \t\t :  0.00000000000000000000003406316535\n",
      "siren \t\t :  1.00000000000000000000000000000000\n",
      "street_music \t\t :  0.00000003555681615807770867832005\n"
     ]
    }
   ],
   "source": [
    "# Class: siren\n",
    "filename = os.path.join(VAL_DIR, \"siren.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "The predicted class is: street_music \n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "air_conditioner \t\t :  0.16020715236663818359375000000000\n",
      "car_horn \t\t :  0.12585353851318359375000000000000\n",
      "children_playing \t\t :  0.00166083616204559803009033203125\n",
      "dog_bark \t\t :  0.00955508183687925338745117187500\n",
      "drilling \t\t :  0.00012191841233288869261741638184\n",
      "engine_idling \t\t :  0.02299744077026844024658203125000\n",
      "gun_shot \t\t :  0.00000187804187135043321177363396\n",
      "jackhammer \t\t :  0.10391051322221755981445312500000\n",
      "siren \t\t :  0.00975450128316879272460937500000\n",
      "street_music \t\t :  0.56593722105026245117187500000000\n"
     ]
    }
   ],
   "source": [
    "# Class: street music\n",
    "filename = os.path.join(VAL_DIR, \"street_music.mp3\")\n",
    "print_prediction(filename) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
