{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "\n",
    "num_rows = 128\n",
    "num_columns = 44\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the Model**\n",
    "<p>Loss function - we will use categorical_crossentropy. This is the most common choice for classification. A lower score indicates that the model is performing better.</p>\n",
    "<p>Metrics - we will use the accuracy metric which will allow us to view the accuracy score on the validation data when we train the model.</p>\n",
    "<p>Optimizer - here we will use adam which is a generally good optimizer for many use cases.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 127, 43, 16)       80        \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 63, 21, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 63, 21, 16)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 62, 20, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 31, 10, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 31, 10, 32)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 30, 9, 64)         8256      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 15, 4, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 15, 4, 64)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 14, 3, 128)        32896     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 7, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 7, 1, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 128)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 3.7243 - accuracy: 0.1151\n",
      "Pre-training accuracy: 11.5054%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 3.8120 - accuracy: 0.1074\n",
      "Epoch 1: val_loss improved from inf to 2.31221, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 9s 300ms/step - loss: 3.8120 - accuracy: 0.1074 - val_loss: 2.3122 - val_accuracy: 0.1317\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.3298 - accuracy: 0.1223\n",
      "Epoch 2: val_loss improved from 2.31221 to 2.28986, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 2.3298 - accuracy: 0.1223 - val_loss: 2.2899 - val_accuracy: 0.1574\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.2485 - accuracy: 0.1350\n",
      "Epoch 3: val_loss improved from 2.28986 to 2.23215, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 2.2485 - accuracy: 0.1350 - val_loss: 2.2322 - val_accuracy: 0.2376\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.1495 - accuracy: 0.1911\n",
      "Epoch 4: val_loss improved from 2.23215 to 2.14457, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 291ms/step - loss: 2.1495 - accuracy: 0.1911 - val_loss: 2.1446 - val_accuracy: 0.2084\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.0184 - accuracy: 0.2497\n",
      "Epoch 5: val_loss improved from 2.14457 to 2.04509, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 2.0184 - accuracy: 0.2497 - val_loss: 2.0451 - val_accuracy: 0.2232\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9196 - accuracy: 0.2826\n",
      "Epoch 6: val_loss improved from 2.04509 to 1.96227, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 296ms/step - loss: 1.9196 - accuracy: 0.2826 - val_loss: 1.9623 - val_accuracy: 0.2954\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.8471 - accuracy: 0.3177\n",
      "Epoch 7: val_loss improved from 1.96227 to 1.88664, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.8471 - accuracy: 0.3177 - val_loss: 1.8866 - val_accuracy: 0.3057\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7984 - accuracy: 0.3406\n",
      "Epoch 8: val_loss improved from 1.88664 to 1.84817, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.7984 - accuracy: 0.3406 - val_loss: 1.8482 - val_accuracy: 0.3314\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7326 - accuracy: 0.3649\n",
      "Epoch 9: val_loss improved from 1.84817 to 1.83406, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.7326 - accuracy: 0.3649 - val_loss: 1.8341 - val_accuracy: 0.3274\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6892 - accuracy: 0.3770\n",
      "Epoch 10: val_loss improved from 1.83406 to 1.75722, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.6892 - accuracy: 0.3770 - val_loss: 1.7572 - val_accuracy: 0.3475\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6483 - accuracy: 0.3953\n",
      "Epoch 11: val_loss improved from 1.75722 to 1.69059, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 297ms/step - loss: 1.6483 - accuracy: 0.3953 - val_loss: 1.6906 - val_accuracy: 0.3658\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6131 - accuracy: 0.4140\n",
      "Epoch 12: val_loss improved from 1.69059 to 1.66858, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 301ms/step - loss: 1.6131 - accuracy: 0.4140 - val_loss: 1.6686 - val_accuracy: 0.3669\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5678 - accuracy: 0.4312\n",
      "Epoch 13: val_loss did not improve from 1.66858\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.5678 - accuracy: 0.4312 - val_loss: 1.6747 - val_accuracy: 0.3583\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5344 - accuracy: 0.4408\n",
      "Epoch 14: val_loss improved from 1.66858 to 1.55801, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 295ms/step - loss: 1.5344 - accuracy: 0.4408 - val_loss: 1.5580 - val_accuracy: 0.4327\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4989 - accuracy: 0.4521\n",
      "Epoch 15: val_loss did not improve from 1.55801\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.4989 - accuracy: 0.4521 - val_loss: 1.5833 - val_accuracy: 0.4076\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4770 - accuracy: 0.4707\n",
      "Epoch 16: val_loss did not improve from 1.55801\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.4770 - accuracy: 0.4707 - val_loss: 1.5847 - val_accuracy: 0.4150\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4591 - accuracy: 0.4820\n",
      "Epoch 17: val_loss did not improve from 1.55801\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.4591 - accuracy: 0.4820 - val_loss: 1.5753 - val_accuracy: 0.4144\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4266 - accuracy: 0.4862\n",
      "Epoch 18: val_loss did not improve from 1.55801\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.4266 - accuracy: 0.4862 - val_loss: 1.5978 - val_accuracy: 0.4156\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4055 - accuracy: 0.4913\n",
      "Epoch 19: val_loss improved from 1.55801 to 1.41307, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.4055 - accuracy: 0.4913 - val_loss: 1.4131 - val_accuracy: 0.4911\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3893 - accuracy: 0.5019\n",
      "Epoch 20: val_loss did not improve from 1.41307\n",
      "28/28 [==============================] - 8s 296ms/step - loss: 1.3893 - accuracy: 0.5019 - val_loss: 1.5003 - val_accuracy: 0.4528\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3842 - accuracy: 0.5015\n",
      "Epoch 21: val_loss did not improve from 1.41307\n",
      "28/28 [==============================] - 8s 295ms/step - loss: 1.3842 - accuracy: 0.5015 - val_loss: 1.5940 - val_accuracy: 0.4287\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3683 - accuracy: 0.5135\n",
      "Epoch 22: val_loss did not improve from 1.41307\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.3683 - accuracy: 0.5135 - val_loss: 1.4522 - val_accuracy: 0.4745\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3250 - accuracy: 0.5304\n",
      "Epoch 23: val_loss did not improve from 1.41307\n",
      "28/28 [==============================] - 8s 296ms/step - loss: 1.3250 - accuracy: 0.5304 - val_loss: 1.4631 - val_accuracy: 0.4814\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3021 - accuracy: 0.5376\n",
      "Epoch 24: val_loss improved from 1.41307 to 1.35724, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.3021 - accuracy: 0.5376 - val_loss: 1.3572 - val_accuracy: 0.5066\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2952 - accuracy: 0.5439\n",
      "Epoch 25: val_loss did not improve from 1.35724\n",
      "28/28 [==============================] - 8s 291ms/step - loss: 1.2952 - accuracy: 0.5439 - val_loss: 1.4566 - val_accuracy: 0.4814\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2915 - accuracy: 0.5413\n",
      "Epoch 26: val_loss did not improve from 1.35724\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.2915 - accuracy: 0.5413 - val_loss: 1.4844 - val_accuracy: 0.4665\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2619 - accuracy: 0.5476\n",
      "Epoch 27: val_loss did not improve from 1.35724\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.2619 - accuracy: 0.5476 - val_loss: 1.3612 - val_accuracy: 0.5129\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2467 - accuracy: 0.5592\n",
      "Epoch 28: val_loss improved from 1.35724 to 1.28483, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.2467 - accuracy: 0.5592 - val_loss: 1.2848 - val_accuracy: 0.5524\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2339 - accuracy: 0.5678\n",
      "Epoch 29: val_loss did not improve from 1.28483\n",
      "28/28 [==============================] - 8s 295ms/step - loss: 1.2339 - accuracy: 0.5678 - val_loss: 1.2944 - val_accuracy: 0.5444\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2066 - accuracy: 0.5731\n",
      "Epoch 30: val_loss improved from 1.28483 to 1.26147, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.2066 - accuracy: 0.5731 - val_loss: 1.2615 - val_accuracy: 0.5610\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2160 - accuracy: 0.5665\n",
      "Epoch 31: val_loss improved from 1.26147 to 1.23367, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.2160 - accuracy: 0.5665 - val_loss: 1.2337 - val_accuracy: 0.5741\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1898 - accuracy: 0.5780\n",
      "Epoch 32: val_loss improved from 1.23367 to 1.22318, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.1898 - accuracy: 0.5780 - val_loss: 1.2232 - val_accuracy: 0.5724\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1888 - accuracy: 0.5759\n",
      "Epoch 33: val_loss did not improve from 1.22318\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.1888 - accuracy: 0.5759 - val_loss: 1.3009 - val_accuracy: 0.5369\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1700 - accuracy: 0.5890\n",
      "Epoch 34: val_loss did not improve from 1.22318\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.1700 - accuracy: 0.5890 - val_loss: 1.2774 - val_accuracy: 0.5489\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1729 - accuracy: 0.5873\n",
      "Epoch 35: val_loss improved from 1.22318 to 1.16487, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.1729 - accuracy: 0.5873 - val_loss: 1.1649 - val_accuracy: 0.6027\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1440 - accuracy: 0.5979\n",
      "Epoch 36: val_loss did not improve from 1.16487\n",
      "28/28 [==============================] - 8s 291ms/step - loss: 1.1440 - accuracy: 0.5979 - val_loss: 1.3128 - val_accuracy: 0.5295\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1357 - accuracy: 0.6007\n",
      "Epoch 37: val_loss did not improve from 1.16487\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.1357 - accuracy: 0.6007 - val_loss: 1.2432 - val_accuracy: 0.5386\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1572 - accuracy: 0.5936\n",
      "Epoch 38: val_loss did not improve from 1.16487\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.1572 - accuracy: 0.5936 - val_loss: 1.2207 - val_accuracy: 0.5730\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1422 - accuracy: 0.5994\n",
      "Epoch 39: val_loss improved from 1.16487 to 1.15736, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.1422 - accuracy: 0.5994 - val_loss: 1.1574 - val_accuracy: 0.6056\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1012 - accuracy: 0.6089\n",
      "Epoch 40: val_loss improved from 1.15736 to 1.10249, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.1012 - accuracy: 0.6089 - val_loss: 1.1025 - val_accuracy: 0.6228\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1288 - accuracy: 0.6066\n",
      "Epoch 41: val_loss did not improve from 1.10249\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.1288 - accuracy: 0.6066 - val_loss: 1.2327 - val_accuracy: 0.5690\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1035 - accuracy: 0.6096\n",
      "Epoch 42: val_loss did not improve from 1.10249\n",
      "28/28 [==============================] - 8s 297ms/step - loss: 1.1035 - accuracy: 0.6096 - val_loss: 1.1266 - val_accuracy: 0.5999\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0838 - accuracy: 0.6236\n",
      "Epoch 43: val_loss improved from 1.10249 to 1.10172, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 300ms/step - loss: 1.0838 - accuracy: 0.6236 - val_loss: 1.1017 - val_accuracy: 0.6199\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1061 - accuracy: 0.6216\n",
      "Epoch 44: val_loss improved from 1.10172 to 1.05503, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.1061 - accuracy: 0.6216 - val_loss: 1.0550 - val_accuracy: 0.6463\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0777 - accuracy: 0.6255\n",
      "Epoch 45: val_loss did not improve from 1.05503\n",
      "28/28 [==============================] - 8s 297ms/step - loss: 1.0777 - accuracy: 0.6255 - val_loss: 1.1063 - val_accuracy: 0.6268\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0641 - accuracy: 0.6288\n",
      "Epoch 46: val_loss did not improve from 1.05503\n",
      "28/28 [==============================] - 8s 295ms/step - loss: 1.0641 - accuracy: 0.6288 - val_loss: 1.1997 - val_accuracy: 0.5736\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0683 - accuracy: 0.6288\n",
      "Epoch 47: val_loss did not improve from 1.05503\n",
      "28/28 [==============================] - 8s 291ms/step - loss: 1.0683 - accuracy: 0.6288 - val_loss: 1.1127 - val_accuracy: 0.6131\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0604 - accuracy: 0.6332\n",
      "Epoch 48: val_loss did not improve from 1.05503\n",
      "28/28 [==============================] - 8s 296ms/step - loss: 1.0604 - accuracy: 0.6332 - val_loss: 1.1483 - val_accuracy: 0.5959\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0428 - accuracy: 0.6387\n",
      "Epoch 49: val_loss did not improve from 1.05503\n",
      "28/28 [==============================] - 8s 295ms/step - loss: 1.0428 - accuracy: 0.6387 - val_loss: 1.2070 - val_accuracy: 0.5844\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0374 - accuracy: 0.6331\n",
      "Epoch 50: val_loss did not improve from 1.05503\n",
      "28/28 [==============================] - 8s 295ms/step - loss: 1.0374 - accuracy: 0.6331 - val_loss: 1.1067 - val_accuracy: 0.6171\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0213 - accuracy: 0.6477\n",
      "Epoch 51: val_loss did not improve from 1.05503\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.0213 - accuracy: 0.6477 - val_loss: 1.0558 - val_accuracy: 0.6382\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0267 - accuracy: 0.6441\n",
      "Epoch 52: val_loss did not improve from 1.05503\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.0267 - accuracy: 0.6441 - val_loss: 1.0773 - val_accuracy: 0.6297\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0041 - accuracy: 0.6501\n",
      "Epoch 53: val_loss improved from 1.05503 to 1.04730, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.0041 - accuracy: 0.6501 - val_loss: 1.0473 - val_accuracy: 0.6319\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0091 - accuracy: 0.6487\n",
      "Epoch 54: val_loss improved from 1.04730 to 1.02544, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 297ms/step - loss: 1.0091 - accuracy: 0.6487 - val_loss: 1.0254 - val_accuracy: 0.6525\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0061 - accuracy: 0.6554\n",
      "Epoch 55: val_loss did not improve from 1.02544\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 1.0061 - accuracy: 0.6554 - val_loss: 1.0335 - val_accuracy: 0.6491\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0184 - accuracy: 0.6458\n",
      "Epoch 56: val_loss did not improve from 1.02544\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 1.0184 - accuracy: 0.6458 - val_loss: 1.1020 - val_accuracy: 0.6176\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.6517\n",
      "Epoch 57: val_loss improved from 1.02544 to 0.98803, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 1.0021 - accuracy: 0.6517 - val_loss: 0.9880 - val_accuracy: 0.6669\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9889 - accuracy: 0.6661\n",
      "Epoch 58: val_loss did not improve from 0.98803\n",
      "28/28 [==============================] - 8s 292ms/step - loss: 0.9889 - accuracy: 0.6661 - val_loss: 1.0452 - val_accuracy: 0.6468\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0010 - accuracy: 0.6531\n",
      "Epoch 59: val_loss did not improve from 0.98803\n",
      "28/28 [==============================] - 8s 301ms/step - loss: 1.0010 - accuracy: 0.6531 - val_loss: 1.0422 - val_accuracy: 0.6337\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.6637\n",
      "Epoch 60: val_loss did not improve from 0.98803\n",
      "28/28 [==============================] - 8s 289ms/step - loss: 0.9802 - accuracy: 0.6637 - val_loss: 1.0776 - val_accuracy: 0.6342\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9714 - accuracy: 0.6574\n",
      "Epoch 61: val_loss improved from 0.98803 to 0.97714, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.9714 - accuracy: 0.6574 - val_loss: 0.9771 - val_accuracy: 0.6669\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9745 - accuracy: 0.6626\n",
      "Epoch 62: val_loss did not improve from 0.97714\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.9745 - accuracy: 0.6626 - val_loss: 1.0305 - val_accuracy: 0.6543\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9595 - accuracy: 0.6694\n",
      "Epoch 63: val_loss improved from 0.97714 to 0.95328, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.9595 - accuracy: 0.6694 - val_loss: 0.9533 - val_accuracy: 0.6880\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9531 - accuracy: 0.6719\n",
      "Epoch 64: val_loss did not improve from 0.95328\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.9531 - accuracy: 0.6719 - val_loss: 1.0082 - val_accuracy: 0.6583\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9474 - accuracy: 0.6737\n",
      "Epoch 65: val_loss did not improve from 0.95328\n",
      "28/28 [==============================] - 8s 285ms/step - loss: 0.9474 - accuracy: 0.6737 - val_loss: 1.0190 - val_accuracy: 0.6629\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9582 - accuracy: 0.6704\n",
      "Epoch 66: val_loss did not improve from 0.95328\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.9582 - accuracy: 0.6704 - val_loss: 1.0073 - val_accuracy: 0.6543\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9471 - accuracy: 0.6739\n",
      "Epoch 67: val_loss improved from 0.95328 to 0.95064, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.9471 - accuracy: 0.6739 - val_loss: 0.9506 - val_accuracy: 0.6869\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.6736\n",
      "Epoch 68: val_loss did not improve from 0.95064\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.9428 - accuracy: 0.6736 - val_loss: 1.0317 - val_accuracy: 0.6617\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9393 - accuracy: 0.6783\n",
      "Epoch 69: val_loss did not improve from 0.95064\n",
      "28/28 [==============================] - 8s 283ms/step - loss: 0.9393 - accuracy: 0.6783 - val_loss: 0.9746 - val_accuracy: 0.6709\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9352 - accuracy: 0.6790\n",
      "Epoch 70: val_loss improved from 0.95064 to 0.92074, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.9352 - accuracy: 0.6790 - val_loss: 0.9207 - val_accuracy: 0.6961\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9198 - accuracy: 0.6896\n",
      "Epoch 71: val_loss did not improve from 0.92074\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 0.9198 - accuracy: 0.6896 - val_loss: 0.9800 - val_accuracy: 0.6783\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9227 - accuracy: 0.6858\n",
      "Epoch 72: val_loss did not improve from 0.92074\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.9227 - accuracy: 0.6858 - val_loss: 1.0181 - val_accuracy: 0.6594\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9128 - accuracy: 0.6862\n",
      "Epoch 73: val_loss did not improve from 0.92074\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.9128 - accuracy: 0.6862 - val_loss: 1.0216 - val_accuracy: 0.6623\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9279 - accuracy: 0.6780\n",
      "Epoch 74: val_loss did not improve from 0.92074\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.9279 - accuracy: 0.6780 - val_loss: 1.0133 - val_accuracy: 0.6617\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8914 - accuracy: 0.6965\n",
      "Epoch 75: val_loss did not improve from 0.92074\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.8914 - accuracy: 0.6965 - val_loss: 1.1379 - val_accuracy: 0.6228\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9223 - accuracy: 0.6872\n",
      "Epoch 76: val_loss did not improve from 0.92074\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.9223 - accuracy: 0.6872 - val_loss: 1.0416 - val_accuracy: 0.6577\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9250 - accuracy: 0.6852\n",
      "Epoch 77: val_loss improved from 0.92074 to 0.90725, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.9250 - accuracy: 0.6852 - val_loss: 0.9073 - val_accuracy: 0.7092\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8905 - accuracy: 0.6988\n",
      "Epoch 78: val_loss did not improve from 0.90725\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.8905 - accuracy: 0.6988 - val_loss: 0.9403 - val_accuracy: 0.6920\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8898 - accuracy: 0.6979\n",
      "Epoch 79: val_loss did not improve from 0.90725\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.8898 - accuracy: 0.6979 - val_loss: 0.9869 - val_accuracy: 0.6737\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8741 - accuracy: 0.7067\n",
      "Epoch 80: val_loss did not improve from 0.90725\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.8741 - accuracy: 0.7067 - val_loss: 0.9744 - val_accuracy: 0.6726\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8820 - accuracy: 0.6946\n",
      "Epoch 81: val_loss improved from 0.90725 to 0.89878, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.8820 - accuracy: 0.6946 - val_loss: 0.8988 - val_accuracy: 0.7046\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8654 - accuracy: 0.7035\n",
      "Epoch 82: val_loss improved from 0.89878 to 0.88027, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 0.8654 - accuracy: 0.7035 - val_loss: 0.8803 - val_accuracy: 0.7098\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8476 - accuracy: 0.7069\n",
      "Epoch 83: val_loss did not improve from 0.88027\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.8476 - accuracy: 0.7069 - val_loss: 0.8867 - val_accuracy: 0.7138\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8539 - accuracy: 0.7094\n",
      "Epoch 84: val_loss did not improve from 0.88027\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.8539 - accuracy: 0.7094 - val_loss: 0.9447 - val_accuracy: 0.6926\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8693 - accuracy: 0.7002\n",
      "Epoch 85: val_loss did not improve from 0.88027\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.8693 - accuracy: 0.7002 - val_loss: 0.9312 - val_accuracy: 0.7006\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8478 - accuracy: 0.7107\n",
      "Epoch 86: val_loss did not improve from 0.88027\n",
      "28/28 [==============================] - 8s 285ms/step - loss: 0.8478 - accuracy: 0.7107 - val_loss: 0.9065 - val_accuracy: 0.7081\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8581 - accuracy: 0.7062\n",
      "Epoch 87: val_loss did not improve from 0.88027\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.8581 - accuracy: 0.7062 - val_loss: 0.9443 - val_accuracy: 0.6909\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8535 - accuracy: 0.7141\n",
      "Epoch 88: val_loss did not improve from 0.88027\n",
      "28/28 [==============================] - 8s 285ms/step - loss: 0.8535 - accuracy: 0.7141 - val_loss: 0.9066 - val_accuracy: 0.7138\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8459 - accuracy: 0.7127\n",
      "Epoch 89: val_loss improved from 0.88027 to 0.84408, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 281ms/step - loss: 0.8459 - accuracy: 0.7127 - val_loss: 0.8441 - val_accuracy: 0.7298\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8413 - accuracy: 0.7079\n",
      "Epoch 90: val_loss did not improve from 0.84408\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.8413 - accuracy: 0.7079 - val_loss: 0.8804 - val_accuracy: 0.7064\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8391 - accuracy: 0.7150\n",
      "Epoch 91: val_loss did not improve from 0.84408\n",
      "28/28 [==============================] - 8s 282ms/step - loss: 0.8391 - accuracy: 0.7150 - val_loss: 0.8455 - val_accuracy: 0.7367\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8151 - accuracy: 0.7203\n",
      "Epoch 92: val_loss did not improve from 0.84408\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.8151 - accuracy: 0.7203 - val_loss: 0.8522 - val_accuracy: 0.7293\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8382 - accuracy: 0.7131\n",
      "Epoch 93: val_loss did not improve from 0.84408\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.8382 - accuracy: 0.7131 - val_loss: 0.8789 - val_accuracy: 0.7086\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8242 - accuracy: 0.7224\n",
      "Epoch 94: val_loss improved from 0.84408 to 0.80245, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.8242 - accuracy: 0.7224 - val_loss: 0.8024 - val_accuracy: 0.7459\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8203 - accuracy: 0.7243\n",
      "Epoch 95: val_loss improved from 0.80245 to 0.79294, saving model to saved_models\\.mels_spectrogram_checkboint.hdf5\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.8203 - accuracy: 0.7243 - val_loss: 0.7929 - val_accuracy: 0.7476\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8158 - accuracy: 0.7247\n",
      "Epoch 96: val_loss did not improve from 0.79294\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 0.8158 - accuracy: 0.7247 - val_loss: 0.8469 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7966 - accuracy: 0.7278\n",
      "Epoch 97: val_loss did not improve from 0.79294\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.7966 - accuracy: 0.7278 - val_loss: 0.7973 - val_accuracy: 0.7544\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8052 - accuracy: 0.7327\n",
      "Epoch 98: val_loss did not improve from 0.79294\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.8052 - accuracy: 0.7327 - val_loss: 0.8153 - val_accuracy: 0.7384\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7984 - accuracy: 0.7273\n",
      "Epoch 99: val_loss did not improve from 0.79294\n",
      "28/28 [==============================] - 8s 287ms/step - loss: 0.7984 - accuracy: 0.7273 - val_loss: 0.8707 - val_accuracy: 0.7155\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7987 - accuracy: 0.7291\n",
      "Epoch 100: val_loss did not improve from 0.79294\n",
      "28/28 [==============================] - 8s 289ms/step - loss: 0.7987 - accuracy: 0.7291 - val_loss: 0.8486 - val_accuracy: 0.7390\n",
      "Training completed in time:  0:13:26.636217\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/.mels_spectrogram_checkboint.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.11438797414302826\n",
      "Testing Accuracy:  0.11505437642335892\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/MelSpectrogram_Classification_Model_2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "\n",
    "# Slice for common length of 2 seconds\n",
    "def slice_audio(librosa_audio, librosa_sample_rate = 22050):\n",
    "    SAMPLE_LENGTH = 2 * librosa_sample_rate\n",
    "\n",
    "    librosa_audio_sliced = librosa_audio[:SAMPLE_LENGTH]\n",
    "    if len(librosa_audio) < SAMPLE_LENGTH:\n",
    "        # print(f\"Audio length {len(librosa_audio)} is less than 2 seconds. Padding with zeros.\")\n",
    "        # np.pad specifies the number of values to add at the beginning and the end of the librosa_audio array.\n",
    "        # 0 -> no padding in the beginning.\n",
    "        # SAMPLE_LENGTH - len(librosa_audio) -> number of zeros to end, ensuring the total length is 2 seconds.\n",
    "        librosa_audio_sliced = np.pad(librosa_audio, (0, SAMPLE_LENGTH - len(librosa_audio)), constant_values=0)\n",
    "    return librosa_audio_sliced\n",
    "\n",
    "\n",
    "def extract_spectrogram(audio_path):\n",
    "    \n",
    "    audio_file, librosa_sample_rate = librosa.load(audio_path, res_type='kaiser_fast')\n",
    "    audio_file = slice_audio(audio_file, librosa_sample_rate)\n",
    "\n",
    "    spectrogram = librosa.stft(audio_file, n_fft=512, win_length=512, dtype=np.float32)\n",
    "    spectrogram = librosa.amplitude_to_db(abs(spectrogram), ref=np.max)\n",
    "    #librosa.display.specshow(spectrogram, sr=librosa_sample_rate, x_axis='time')\n",
    "\n",
    "    # spectrogram = tf.expand_dims(spectrogram, axis = 2)\n",
    "\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_spectrogram(file_name)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = np.argmax(model.predict(prediction_feature), axis=-1)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**\n",
    "<p>On new samples<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('saved_models/Spectrogram_Classification_Model.keras')\n",
    "\n",
    "VAL_DIR = \"D:\\\\Code\\\\ProjectsPython\\\\ML_TrainingGround\\\\ML_Audio\\\\data\\\\UrbanSound8K\\\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 88665 into shape (1,128,44,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\Tensorflow\\c2_Model_Training_Mel_Spectrograms.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/c2_Model_Training_Mel_Spectrograms.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Class: Air Conditioner\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/c2_Model_Training_Mel_Spectrograms.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(VAL_DIR, \u001b[39m\"\u001b[39m\u001b[39mair_conditioner.mp3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/c2_Model_Training_Mel_Spectrograms.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m print_prediction(filename)\n",
      "\u001b[1;32md:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\Tensorflow\\c2_Model_Training_Mel_Spectrograms.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/c2_Model_Training_Mel_Spectrograms.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_prediction\u001b[39m(file_name):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/c2_Model_Training_Mel_Spectrograms.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     prediction_feature \u001b[39m=\u001b[39m extract_spectrogram(file_name)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/c2_Model_Training_Mel_Spectrograms.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     prediction_feature \u001b[39m=\u001b[39m prediction_feature\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, num_rows, num_columns, num_channels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/c2_Model_Training_Mel_Spectrograms.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     predicted_vector \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(model\u001b[39m.\u001b[39mpredict(prediction_feature), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/c2_Model_Training_Mel_Spectrograms.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     predicted_class \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39minverse_transform(predicted_vector) \n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 88665 into shape (1,128,44,1)"
     ]
    }
   ],
   "source": [
    "# Class: Air Conditioner\n",
    "filename = os.path.join(VAL_DIR, \"air_conditioner.mp3\")\n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "The predicted class is: engine_idling \n",
      "\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "air_conditioner \t\t :  0.19074751436710357666015625000000\n",
      "car_horn \t\t :  0.00494202831760048866271972656250\n",
      "children_playing \t\t :  0.01620393991470336914062500000000\n",
      "dog_bark \t\t :  0.00649807881563901901245117187500\n",
      "drilling \t\t :  0.01107691135257482528686523437500\n",
      "engine_idling \t\t :  0.62436318397521972656250000000000\n",
      "gun_shot \t\t :  0.01037050131708383560180664062500\n",
      "jackhammer \t\t :  0.05050666257739067077636718750000\n",
      "siren \t\t :  0.06733405590057373046875000000000\n",
      "street_music \t\t :  0.01795705407857894897460937500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:362: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., :off_start] = fft.rfft(fft_window * y_frames_pre, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:366: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., -off_end:] = fft.rfft(fft_window * y_frames_post, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n"
     ]
    }
   ],
   "source": [
    "# Class: Car idle\n",
    "filename = os.path.join(VAL_DIR, \"car_idle.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "The predicted class is: siren \n",
      "\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "air_conditioner \t\t :  0.04661423712968826293945312500000\n",
      "car_horn \t\t :  0.08865276724100112915039062500000\n",
      "children_playing \t\t :  0.11344639956951141357421875000000\n",
      "dog_bark \t\t :  0.13278207182884216308593750000000\n",
      "drilling \t\t :  0.08890788257122039794921875000000\n",
      "engine_idling \t\t :  0.04933480918407440185546875000000\n",
      "gun_shot \t\t :  0.03988853842020034790039062500000\n",
      "jackhammer \t\t :  0.06437175720930099487304687500000\n",
      "siren \t\t :  0.24432623386383056640625000000000\n",
      "street_music \t\t :  0.13167531788349151611328125000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:362: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., :off_start] = fft.rfft(fft_window * y_frames_pre, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:366: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., -off_end:] = fft.rfft(fft_window * y_frames_post, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n"
     ]
    }
   ],
   "source": [
    "# Class: dog bark\n",
    "filename = os.path.join(VAL_DIR, \"dog_barking.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "The predicted class is: siren \n",
      "\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "air_conditioner \t\t :  0.00457365065813064575195312500000\n",
      "car_horn \t\t :  0.01387429982423782348632812500000\n",
      "children_playing \t\t :  0.00199420424178242683410644531250\n",
      "dog_bark \t\t :  0.00151245389133691787719726562500\n",
      "drilling \t\t :  0.41210639476776123046875000000000\n",
      "engine_idling \t\t :  0.00198868243023753166198730468750\n",
      "gun_shot \t\t :  0.00001093672017304925248026847839\n",
      "jackhammer \t\t :  0.03502830117940902709960937500000\n",
      "siren \t\t :  0.52517592906951904296875000000000\n",
      "street_music \t\t :  0.00373518071137368679046630859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:362: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., :off_start] = fft.rfft(fft_window * y_frames_pre, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:366: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., -off_end:] = fft.rfft(fft_window * y_frames_post, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n"
     ]
    }
   ],
   "source": [
    "# Class: drill\n",
    "filename = os.path.join(VAL_DIR, \"drill.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "The predicted class is: siren \n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "air_conditioner \t\t :  0.02664410322904586791992187500000\n",
      "car_horn \t\t :  0.02038235776126384735107421875000\n",
      "children_playing \t\t :  0.06551940739154815673828125000000\n",
      "dog_bark \t\t :  0.04880893230438232421875000000000\n",
      "drilling \t\t :  0.16975186765193939208984375000000\n",
      "engine_idling \t\t :  0.04078878834843635559082031250000\n",
      "gun_shot \t\t :  0.00293349893763661384582519531250\n",
      "jackhammer \t\t :  0.23104561865329742431640625000000\n",
      "siren \t\t :  0.36358994245529174804687500000000\n",
      "street_music \t\t :  0.03053554147481918334960937500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:362: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., :off_start] = fft.rfft(fft_window * y_frames_pre, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:366: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., -off_end:] = fft.rfft(fft_window * y_frames_post, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n"
     ]
    }
   ],
   "source": [
    "# Class: jackhammer\n",
    "filename = os.path.join(VAL_DIR, \"jackhammer.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "The predicted class is: siren \n",
      "\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:362: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., :off_start] = fft.rfft(fft_window * y_frames_pre, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:366: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., -off_end:] = fft.rfft(fft_window * y_frames_post, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_conditioner \t\t :  0.00301683344878256320953369140625\n",
      "car_horn \t\t :  0.10142213106155395507812500000000\n",
      "children_playing \t\t :  0.11878542602062225341796875000000\n",
      "dog_bark \t\t :  0.04199254512786865234375000000000\n",
      "drilling \t\t :  0.03343436121940612792968750000000\n",
      "engine_idling \t\t :  0.00188155565410852432250976562500\n",
      "gun_shot \t\t :  0.00051945296581834554672241210938\n",
      "jackhammer \t\t :  0.01036619301885366439819335937500\n",
      "siren \t\t :  0.54443687200546264648437500000000\n",
      "street_music \t\t :  0.14414460957050323486328125000000\n"
     ]
    }
   ],
   "source": [
    "# Class: kids playing\n",
    "filename = os.path.join(VAL_DIR, \"kids_playing.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "The predicted class is: siren \n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "air_conditioner \t\t :  0.00001835819057305343449115753174\n",
      "car_horn \t\t :  0.02222104184329509735107421875000\n",
      "children_playing \t\t :  0.00399238662794232368469238281250\n",
      "dog_bark \t\t :  0.00138486456125974655151367187500\n",
      "drilling \t\t :  0.00384465279057621955871582031250\n",
      "engine_idling \t\t :  0.00001672653343121055513620376587\n",
      "gun_shot \t\t :  0.00000098241787327424390241503716\n",
      "jackhammer \t\t :  0.00066541740670800209045410156250\n",
      "siren \t\t :  0.94724416732788085937500000000000\n",
      "street_music \t\t :  0.02061129733920097351074218750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:362: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., :off_start] = fft.rfft(fft_window * y_frames_pre, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:366: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., -off_end:] = fft.rfft(fft_window * y_frames_post, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n"
     ]
    }
   ],
   "source": [
    "# Class: siren\n",
    "filename = os.path.join(VAL_DIR, \"siren.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "The predicted class is: street_music \n",
      "\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "air_conditioner \t\t :  0.04146852344274520874023437500000\n",
      "car_horn \t\t :  0.09178592264652252197265625000000\n",
      "children_playing \t\t :  0.04445578157901763916015625000000\n",
      "dog_bark \t\t :  0.02995055913925170898437500000000\n",
      "drilling \t\t :  0.04206641390919685363769531250000\n",
      "engine_idling \t\t :  0.03835495933890342712402343750000\n",
      "gun_shot \t\t :  0.00504108518362045288085937500000\n",
      "jackhammer \t\t :  0.05032153427600860595703125000000\n",
      "siren \t\t :  0.11103385686874389648437500000000\n",
      "street_music \t\t :  0.54552137851715087890625000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:362: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., :off_start] = fft.rfft(fft_window * y_frames_pre, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:366: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., -off_end:] = fft.rfft(fft_window * y_frames_post, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n"
     ]
    }
   ],
   "source": [
    "# Class: street music\n",
    "filename = os.path.join(VAL_DIR, \"street_music.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
