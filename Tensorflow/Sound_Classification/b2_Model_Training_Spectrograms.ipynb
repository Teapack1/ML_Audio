{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6985, 257, 126)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "\n",
    "num_rows = 257\n",
    "num_columns = 126\n",
    "num_channels = 1\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the Model**\n",
    "<p>Loss function - we will use categorical_crossentropy. This is the most common choice for classification. A lower score indicates that the model is performing better.</p>\n",
    "<p>Metrics - we will use the accuracy metric which will allow us to view the accuracy score on the validation data when we train the model.</p>\n",
    "<p>Optimizer - here we will use adam which is a generally good optimizer for many use cases.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 125, 16)      80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 62, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128, 62, 16)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 127, 61, 32)       2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 63, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 63, 30, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 62, 29, 64)        8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 31, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 31, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 30, 13, 128)       32896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 15, 6, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 15, 6, 128)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "55/55 [==============================] - 4s 54ms/step - loss: 4.8163 - accuracy: 0.0767\n",
      "Pre-training accuracy: 7.6703%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 5.9629 - accuracy: 0.1094\n",
      "Epoch 1: val_loss improved from inf to 2.39909, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 53s 2s/step - loss: 5.9629 - accuracy: 0.1094 - val_loss: 2.3991 - val_accuracy: 0.1151\n",
      "Epoch 2/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.3665 - accuracy: 0.1512\n",
      "Epoch 2: val_loss improved from 2.39909 to 2.31486, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 52s 2s/step - loss: 2.3665 - accuracy: 0.1512 - val_loss: 2.3149 - val_accuracy: 0.1883\n",
      "Epoch 3/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.1511 - accuracy: 0.2136\n",
      "Epoch 3: val_loss improved from 2.31486 to 2.19259, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 51s 2s/step - loss: 2.1511 - accuracy: 0.2136 - val_loss: 2.1926 - val_accuracy: 0.2313\n",
      "Epoch 4/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.0468 - accuracy: 0.2399\n",
      "Epoch 4: val_loss improved from 2.19259 to 2.11973, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 52s 2s/step - loss: 2.0468 - accuracy: 0.2399 - val_loss: 2.1197 - val_accuracy: 0.2284\n",
      "Epoch 5/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.0246 - accuracy: 0.2378\n",
      "Epoch 5: val_loss improved from 2.11973 to 2.08838, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 51s 2s/step - loss: 2.0246 - accuracy: 0.2378 - val_loss: 2.0884 - val_accuracy: 0.2232\n",
      "Epoch 6/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.0036 - accuracy: 0.2465\n",
      "Epoch 6: val_loss improved from 2.08838 to 2.07683, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 52s 2s/step - loss: 2.0036 - accuracy: 0.2465 - val_loss: 2.0768 - val_accuracy: 0.2295\n",
      "Epoch 7/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9909 - accuracy: 0.2460\n",
      "Epoch 7: val_loss improved from 2.07683 to 2.06254, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.9909 - accuracy: 0.2460 - val_loss: 2.0625 - val_accuracy: 0.2433\n",
      "Epoch 8/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9723 - accuracy: 0.2568\n",
      "Epoch 8: val_loss did not improve from 2.06254\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.9723 - accuracy: 0.2568 - val_loss: 2.0678 - val_accuracy: 0.2719\n",
      "Epoch 9/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9542 - accuracy: 0.2574\n",
      "Epoch 9: val_loss improved from 2.06254 to 2.03067, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.9542 - accuracy: 0.2574 - val_loss: 2.0307 - val_accuracy: 0.2622\n",
      "Epoch 10/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9386 - accuracy: 0.2623\n",
      "Epoch 10: val_loss improved from 2.03067 to 2.01849, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.9386 - accuracy: 0.2623 - val_loss: 2.0185 - val_accuracy: 0.2604\n",
      "Epoch 11/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9136 - accuracy: 0.2757\n",
      "Epoch 11: val_loss improved from 2.01849 to 2.01581, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.9136 - accuracy: 0.2757 - val_loss: 2.0158 - val_accuracy: 0.2713\n",
      "Epoch 12/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.8940 - accuracy: 0.2729\n",
      "Epoch 12: val_loss improved from 2.01581 to 1.99987, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.8940 - accuracy: 0.2729 - val_loss: 1.9999 - val_accuracy: 0.2736\n",
      "Epoch 13/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.8759 - accuracy: 0.2855\n",
      "Epoch 13: val_loss did not improve from 1.99987\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.8759 - accuracy: 0.2855 - val_loss: 2.0075 - val_accuracy: 0.2679\n",
      "Epoch 14/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.8464 - accuracy: 0.2926\n",
      "Epoch 14: val_loss did not improve from 1.99987\n",
      "28/28 [==============================] - 52s 2s/step - loss: 1.8464 - accuracy: 0.2926 - val_loss: 2.0383 - val_accuracy: 0.2685\n",
      "Epoch 15/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.8188 - accuracy: 0.3151\n",
      "Epoch 15: val_loss did not improve from 1.99987\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.8188 - accuracy: 0.3151 - val_loss: 2.0942 - val_accuracy: 0.2587\n",
      "Epoch 16/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7877 - accuracy: 0.3296\n",
      "Epoch 16: val_loss did not improve from 1.99987\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.7877 - accuracy: 0.3296 - val_loss: 2.0687 - val_accuracy: 0.2805\n",
      "Epoch 17/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7524 - accuracy: 0.3383\n",
      "Epoch 17: val_loss did not improve from 1.99987\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.7524 - accuracy: 0.3383 - val_loss: 2.0881 - val_accuracy: 0.2707\n",
      "Epoch 18/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7370 - accuracy: 0.3460\n",
      "Epoch 18: val_loss did not improve from 1.99987\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.7370 - accuracy: 0.3460 - val_loss: 2.0068 - val_accuracy: 0.2851\n",
      "Epoch 19/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7137 - accuracy: 0.3489\n",
      "Epoch 19: val_loss did not improve from 1.99987\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.7137 - accuracy: 0.3489 - val_loss: 2.0728 - val_accuracy: 0.2788\n",
      "Epoch 20/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7176 - accuracy: 0.3586\n",
      "Epoch 20: val_loss improved from 1.99987 to 1.94975, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.7176 - accuracy: 0.3586 - val_loss: 1.9497 - val_accuracy: 0.3051\n",
      "Epoch 21/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6934 - accuracy: 0.3651\n",
      "Epoch 21: val_loss did not improve from 1.94975\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.6934 - accuracy: 0.3651 - val_loss: 1.9713 - val_accuracy: 0.3120\n",
      "Epoch 22/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6600 - accuracy: 0.3748\n",
      "Epoch 22: val_loss did not improve from 1.94975\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.6600 - accuracy: 0.3748 - val_loss: 2.0582 - val_accuracy: 0.2988\n",
      "Epoch 23/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6380 - accuracy: 0.3825\n",
      "Epoch 23: val_loss did not improve from 1.94975\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.6380 - accuracy: 0.3825 - val_loss: 2.0868 - val_accuracy: 0.2971\n",
      "Epoch 24/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6261 - accuracy: 0.3894\n",
      "Epoch 24: val_loss did not improve from 1.94975\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.6261 - accuracy: 0.3894 - val_loss: 1.9933 - val_accuracy: 0.3223\n",
      "Epoch 25/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6135 - accuracy: 0.4019\n",
      "Epoch 25: val_loss did not improve from 1.94975\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.6135 - accuracy: 0.4019 - val_loss: 1.9955 - val_accuracy: 0.3171\n",
      "Epoch 26/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6008 - accuracy: 0.3967\n",
      "Epoch 26: val_loss did not improve from 1.94975\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.6008 - accuracy: 0.3967 - val_loss: 2.0082 - val_accuracy: 0.3217\n",
      "Epoch 27/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6102 - accuracy: 0.4036\n",
      "Epoch 27: val_loss improved from 1.94975 to 1.87851, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.6102 - accuracy: 0.4036 - val_loss: 1.8785 - val_accuracy: 0.3440\n",
      "Epoch 28/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5790 - accuracy: 0.4176\n",
      "Epoch 28: val_loss did not improve from 1.87851\n",
      "28/28 [==============================] - 51s 2s/step - loss: 1.5790 - accuracy: 0.4176 - val_loss: 1.8859 - val_accuracy: 0.3452\n",
      "Epoch 29/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5451 - accuracy: 0.4381\n",
      "Epoch 29: val_loss did not improve from 1.87851\n",
      "28/28 [==============================] - 52s 2s/step - loss: 1.5451 - accuracy: 0.4381 - val_loss: 1.8989 - val_accuracy: 0.3469\n",
      "Epoch 30/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5666 - accuracy: 0.4243\n",
      "Epoch 30: val_loss did not improve from 1.87851\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.5666 - accuracy: 0.4243 - val_loss: 1.9818 - val_accuracy: 0.3274\n",
      "Epoch 31/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5316 - accuracy: 0.4397\n",
      "Epoch 31: val_loss did not improve from 1.87851\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.5316 - accuracy: 0.4397 - val_loss: 1.9153 - val_accuracy: 0.3360\n",
      "Epoch 32/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5445 - accuracy: 0.4368\n",
      "Epoch 32: val_loss improved from 1.87851 to 1.81489, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.5445 - accuracy: 0.4368 - val_loss: 1.8149 - val_accuracy: 0.3543\n",
      "Epoch 33/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5129 - accuracy: 0.4513\n",
      "Epoch 33: val_loss improved from 1.81489 to 1.74800, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.5129 - accuracy: 0.4513 - val_loss: 1.7480 - val_accuracy: 0.3818\n",
      "Epoch 34/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5146 - accuracy: 0.4462\n",
      "Epoch 34: val_loss did not improve from 1.74800\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.5146 - accuracy: 0.4462 - val_loss: 1.8601 - val_accuracy: 0.3412\n",
      "Epoch 35/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5061 - accuracy: 0.4418\n",
      "Epoch 35: val_loss did not improve from 1.74800\n",
      "28/28 [==============================] - 50s 2s/step - loss: 1.5061 - accuracy: 0.4418 - val_loss: 1.8260 - val_accuracy: 0.3629\n",
      "Epoch 36/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4944 - accuracy: 0.4573\n",
      "Epoch 36: val_loss improved from 1.74800 to 1.74249, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4944 - accuracy: 0.4573 - val_loss: 1.7425 - val_accuracy: 0.3858\n",
      "Epoch 37/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5026 - accuracy: 0.4494\n",
      "Epoch 37: val_loss did not improve from 1.74249\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.5026 - accuracy: 0.4494 - val_loss: 1.7665 - val_accuracy: 0.3812\n",
      "Epoch 38/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4798 - accuracy: 0.4606\n",
      "Epoch 38: val_loss did not improve from 1.74249\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4798 - accuracy: 0.4606 - val_loss: 1.7636 - val_accuracy: 0.3864\n",
      "Epoch 39/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4744 - accuracy: 0.4618\n",
      "Epoch 39: val_loss did not improve from 1.74249\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4744 - accuracy: 0.4618 - val_loss: 1.8297 - val_accuracy: 0.3663\n",
      "Epoch 40/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4580 - accuracy: 0.4674\n",
      "Epoch 40: val_loss did not improve from 1.74249\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4580 - accuracy: 0.4674 - val_loss: 1.9606 - val_accuracy: 0.3555\n",
      "Epoch 41/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4735 - accuracy: 0.4608\n",
      "Epoch 41: val_loss improved from 1.74249 to 1.68883, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4735 - accuracy: 0.4608 - val_loss: 1.6888 - val_accuracy: 0.4087\n",
      "Epoch 42/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4516 - accuracy: 0.4759\n",
      "Epoch 42: val_loss did not improve from 1.68883\n",
      "28/28 [==============================] - 48s 2s/step - loss: 1.4516 - accuracy: 0.4759 - val_loss: 1.7228 - val_accuracy: 0.4047\n",
      "Epoch 43/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4305 - accuracy: 0.4800\n",
      "Epoch 43: val_loss did not improve from 1.68883\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4305 - accuracy: 0.4800 - val_loss: 1.6900 - val_accuracy: 0.4161\n",
      "Epoch 44/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4522 - accuracy: 0.4787\n",
      "Epoch 44: val_loss did not improve from 1.68883\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4522 - accuracy: 0.4787 - val_loss: 1.7005 - val_accuracy: 0.4041\n",
      "Epoch 45/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4116 - accuracy: 0.4909\n",
      "Epoch 45: val_loss improved from 1.68883 to 1.67533, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4116 - accuracy: 0.4909 - val_loss: 1.6753 - val_accuracy: 0.4196\n",
      "Epoch 46/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4024 - accuracy: 0.4879\n",
      "Epoch 46: val_loss did not improve from 1.67533\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4024 - accuracy: 0.4879 - val_loss: 1.7592 - val_accuracy: 0.4018\n",
      "Epoch 47/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4104 - accuracy: 0.4926\n",
      "Epoch 47: val_loss did not improve from 1.67533\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4104 - accuracy: 0.4926 - val_loss: 1.8179 - val_accuracy: 0.3847\n",
      "Epoch 48/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4173 - accuracy: 0.4848\n",
      "Epoch 48: val_loss improved from 1.67533 to 1.63099, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4173 - accuracy: 0.4848 - val_loss: 1.6310 - val_accuracy: 0.4488\n",
      "Epoch 49/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4165 - accuracy: 0.4843\n",
      "Epoch 49: val_loss did not improve from 1.63099\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.4165 - accuracy: 0.4843 - val_loss: 1.6661 - val_accuracy: 0.4270\n",
      "Epoch 50/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3883 - accuracy: 0.5024\n",
      "Epoch 50: val_loss improved from 1.63099 to 1.61059, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3883 - accuracy: 0.5024 - val_loss: 1.6106 - val_accuracy: 0.4465\n",
      "Epoch 51/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3854 - accuracy: 0.5038\n",
      "Epoch 51: val_loss improved from 1.61059 to 1.56794, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3854 - accuracy: 0.5038 - val_loss: 1.5679 - val_accuracy: 0.4585\n",
      "Epoch 52/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3725 - accuracy: 0.5067\n",
      "Epoch 52: val_loss did not improve from 1.56794\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3725 - accuracy: 0.5067 - val_loss: 1.6862 - val_accuracy: 0.4213\n",
      "Epoch 53/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3970 - accuracy: 0.4994\n",
      "Epoch 53: val_loss did not improve from 1.56794\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3970 - accuracy: 0.4994 - val_loss: 1.5924 - val_accuracy: 0.4562\n",
      "Epoch 54/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3499 - accuracy: 0.5157\n",
      "Epoch 54: val_loss did not improve from 1.56794\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3499 - accuracy: 0.5157 - val_loss: 1.6086 - val_accuracy: 0.4482\n",
      "Epoch 55/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3460 - accuracy: 0.5193\n",
      "Epoch 55: val_loss improved from 1.56794 to 1.55634, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3460 - accuracy: 0.5193 - val_loss: 1.5563 - val_accuracy: 0.4602\n",
      "Epoch 56/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3345 - accuracy: 0.5214\n",
      "Epoch 56: val_loss improved from 1.55634 to 1.49842, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3345 - accuracy: 0.5214 - val_loss: 1.4984 - val_accuracy: 0.4843\n",
      "Epoch 57/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3594 - accuracy: 0.5065\n",
      "Epoch 57: val_loss did not improve from 1.49842\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3594 - accuracy: 0.5065 - val_loss: 1.6590 - val_accuracy: 0.4448\n",
      "Epoch 58/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3604 - accuracy: 0.5068\n",
      "Epoch 58: val_loss did not improve from 1.49842\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3604 - accuracy: 0.5068 - val_loss: 1.5741 - val_accuracy: 0.4665\n",
      "Epoch 59/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3340 - accuracy: 0.5184\n",
      "Epoch 59: val_loss did not improve from 1.49842\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3340 - accuracy: 0.5184 - val_loss: 1.6534 - val_accuracy: 0.4448\n",
      "Epoch 60/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3330 - accuracy: 0.5223\n",
      "Epoch 60: val_loss did not improve from 1.49842\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3330 - accuracy: 0.5223 - val_loss: 1.5757 - val_accuracy: 0.4694\n",
      "Epoch 61/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3004 - accuracy: 0.5314\n",
      "Epoch 61: val_loss did not improve from 1.49842\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3004 - accuracy: 0.5314 - val_loss: 1.5100 - val_accuracy: 0.4780\n",
      "Epoch 62/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3199 - accuracy: 0.5248\n",
      "Epoch 62: val_loss improved from 1.49842 to 1.47485, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3199 - accuracy: 0.5248 - val_loss: 1.4748 - val_accuracy: 0.5003\n",
      "Epoch 63/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3271 - accuracy: 0.5274\n",
      "Epoch 63: val_loss did not improve from 1.47485\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3271 - accuracy: 0.5274 - val_loss: 1.5019 - val_accuracy: 0.4906\n",
      "Epoch 64/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3010 - accuracy: 0.5306\n",
      "Epoch 64: val_loss did not improve from 1.47485\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.3010 - accuracy: 0.5306 - val_loss: 1.5076 - val_accuracy: 0.4831\n",
      "Epoch 65/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2894 - accuracy: 0.5399\n",
      "Epoch 65: val_loss did not improve from 1.47485\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.2894 - accuracy: 0.5399 - val_loss: 1.5883 - val_accuracy: 0.4602\n",
      "Epoch 66/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2945 - accuracy: 0.5386\n",
      "Epoch 66: val_loss did not improve from 1.47485\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.2945 - accuracy: 0.5386 - val_loss: 1.4753 - val_accuracy: 0.4911\n",
      "Epoch 67/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2908 - accuracy: 0.5380\n",
      "Epoch 67: val_loss did not improve from 1.47485\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.2908 - accuracy: 0.5380 - val_loss: 1.4802 - val_accuracy: 0.5043\n",
      "Epoch 68/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2828 - accuracy: 0.5410\n",
      "Epoch 68: val_loss improved from 1.47485 to 1.46076, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.2828 - accuracy: 0.5410 - val_loss: 1.4608 - val_accuracy: 0.4963\n",
      "Epoch 69/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2691 - accuracy: 0.5456\n",
      "Epoch 69: val_loss improved from 1.46076 to 1.42239, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.2691 - accuracy: 0.5456 - val_loss: 1.4224 - val_accuracy: 0.5157\n",
      "Epoch 70/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2723 - accuracy: 0.5509\n",
      "Epoch 70: val_loss did not improve from 1.42239\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.2723 - accuracy: 0.5509 - val_loss: 1.5077 - val_accuracy: 0.4986\n",
      "Epoch 71/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2494 - accuracy: 0.5586\n",
      "Epoch 71: val_loss did not improve from 1.42239\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.2494 - accuracy: 0.5586 - val_loss: 1.5645 - val_accuracy: 0.4825\n",
      "Epoch 72/72\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2521 - accuracy: 0.5562\n",
      "Epoch 72: val_loss improved from 1.42239 to 1.40428, saving model to saved_models\\spectrogramweights.best.basic_cnn.hdf5\n",
      "28/28 [==============================] - 49s 2s/step - loss: 1.2521 - accuracy: 0.5562 - val_loss: 1.4043 - val_accuracy: 0.5232\n",
      "Training completed in time:  0:59:35.042576\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from datetime import datetime \n",
    "import os\n",
    "\n",
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/spectrogramweights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.53214031457901\n",
      "Testing Accuracy:  0.5231825709342957\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/Spectrogram_Classification_Model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "\n",
    "# Slice for common length of 2 seconds\n",
    "def slice_audio(librosa_audio, librosa_sample_rate = 22050):\n",
    "    SAMPLE_LENGTH = 2 * librosa_sample_rate\n",
    "\n",
    "    librosa_audio_sliced = librosa_audio[:SAMPLE_LENGTH]\n",
    "    if len(librosa_audio) < SAMPLE_LENGTH:\n",
    "        # print(f\"Audio length {len(librosa_audio)} is less than 2 seconds. Padding with zeros.\")\n",
    "        # np.pad specifies the number of values to add at the beginning and the end of the librosa_audio array.\n",
    "        # 0 -> no padding in the beginning.\n",
    "        # SAMPLE_LENGTH - len(librosa_audio) -> number of zeros to end, ensuring the total length is 2 seconds.\n",
    "        librosa_audio_sliced = np.pad(librosa_audio, (0, SAMPLE_LENGTH - len(librosa_audio)), constant_values=0)\n",
    "    return librosa_audio_sliced\n",
    "\n",
    "\n",
    "def extract_spectrogram(audio_path):\n",
    "    \n",
    "    audio_file, librosa_sample_rate = librosa.load(audio_path, sr=SAMPLE_RATE, res_type='kaiser_fast')\n",
    "    audio_file = slice_audio(audio_file, librosa_sample_rate)\n",
    "\n",
    "    spectrogram = librosa.stft(audio_file, n_fft=512, win_length=256, dtype=np.float32)\n",
    "    spectrogram = librosa.amplitude_to_db(abs(spectrogram), ref=np.max)\n",
    "    #librosa.display.specshow(spectrogram, sr=librosa_sample_rate, x_axis='time')\n",
    "\n",
    "    # spectrogram = tf.expand_dims(spectrogram, axis = 2)\n",
    "\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_spectrogram(file_name)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = np.argmax(model.predict(prediction_feature), axis=-1)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**\n",
    "<p>On new samples<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('saved_models/Spectrogram_Classification_Model.keras')\n",
    "\n",
    "VAL_DIR = \"D:\\\\Code\\\\ProjectsPython\\\\ML_TrainingGround\\\\ML_Audio\\\\data\\\\UrbanSound8K\\\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:362: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., :off_start] = fft.rfft(fft_window * y_frames_pre, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:366: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., -off_end:] = fft.rfft(fft_window * y_frames_post, axis=-2)\n",
      "d:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 128757 into shape (1,257,126,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\Tensorflow\\b2_Model_Training_Spectrograms.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/b2_Model_Training_Spectrograms.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Class: Air Conditioner\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/b2_Model_Training_Spectrograms.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(VAL_DIR, \u001b[39m\"\u001b[39m\u001b[39mair_conditioner.mp3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/b2_Model_Training_Spectrograms.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m print_prediction(filename)\n",
      "\u001b[1;32md:\\Code\\ProjectsPython\\ML_TrainingGround\\ML_Audio\\Tensorflow\\b2_Model_Training_Spectrograms.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/b2_Model_Training_Spectrograms.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_prediction\u001b[39m(file_name):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/b2_Model_Training_Spectrograms.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     prediction_feature \u001b[39m=\u001b[39m extract_spectrogram(file_name)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/b2_Model_Training_Spectrograms.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     prediction_feature \u001b[39m=\u001b[39m prediction_feature\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, num_rows, num_columns, num_channels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/b2_Model_Training_Spectrograms.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     predicted_vector \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(model\u001b[39m.\u001b[39mpredict(prediction_feature), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/ProjectsPython/ML_TrainingGround/ML_Audio/Tensorflow/b2_Model_Training_Spectrograms.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     predicted_class \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39minverse_transform(predicted_vector) \n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 128757 into shape (1,257,126,1)"
     ]
    }
   ],
   "source": [
    "# Class: Air Conditioner\n",
    "filename = os.path.join(VAL_DIR, \"air_conditioner.mp3\")\n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: Car idle\n",
    "filename = os.path.join(VAL_DIR, \"car_idle.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: dog bark\n",
    "filename = os.path.join(VAL_DIR, \"dog_barking.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: drill\n",
    "filename = os.path.join(VAL_DIR, \"drill.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: jackhammer\n",
    "filename = os.path.join(VAL_DIR, \"jackhammer.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: kids playing\n",
    "filename = os.path.join(VAL_DIR, \"kids_playing.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: siren\n",
    "filename = os.path.join(VAL_DIR, \"siren.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: street music\n",
    "filename = os.path.join(VAL_DIR, \"street_music.mp3\")\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
