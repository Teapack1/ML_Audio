{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing CNN for Sound Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN layers parameters consist of a set of learnable filters (or kernels), \n",
    "which have a small receptive field, but extend through the full depth of the \n",
    "input volume. Their role is to slide (or convolve) across the input data \n",
    "(such as an image) to produce a feature map or activation map.\n",
    "\n",
    "Convolution: The filter slides over the input image. At every position, a matrix multiplication is performed between the filter and the part of the image it's currently on. This results in a single pixel in the output feature map. This process is repeated across the entire image.\n",
    "\n",
    "Activation: After convolution, an activation function (like ReLU) is applied to introduce non-linearity to the model. This allows the model to learn more complex patterns.\n",
    "\n",
    "Pooling: This step reduces the spatial dimensions of the feature map, retaining the most important information.\n",
    "\n",
    "Fully Connected Layers: After several rounds of convolution and pooling, the data is flattened and passed through one or more fully connected layers to determine the final class or classes of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model calss will inherit from nn.Module\n",
    "class CNNNetwork(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        # The super() function returns a temporary object of the superclass (nn.Module in this case), allowing you to call its methods. \n",
    "        # The __init__() method of the superclass is explicitly called within the child class.\n",
    "        super().__init__()\n",
    "        # We will use 4 CNN blocks. Each cnn block will go through -> flattern / linear/ softmax (10 classes in our case)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # 1 channel for grayscale image\n",
    "                out_channels=16,    # 16 filters (kernels), This means the layer will produce 16 feature maps as output.\n",
    "                kernel_size=3,      # (3x3) A filter (or kernel) is a smaller-sized matrix in terms of width and height. It's used to slide over the input data (like an image) to produce a feature map. \n",
    "                stride=1,           # controls how the filter convolves around the input volume. A stride of 1 moves the filter one pixel at a time\n",
    "                padding=2           # Padding is used to add layers of zeros to the outside of the input volume. \n",
    "            ),\n",
    "            #Rectified linear unit\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16, # Equal to the out_channels of the previous layer.     \n",
    "                out_channels=32,    \n",
    "                kernel_size=3,     \n",
    "                stride=1,         \n",
    "                padding=2\n",
    "            ),\n",
    "            #Rectified linear unit\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "            \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,      \n",
    "                out_channels=64,    \n",
    "                kernel_size=3,     \n",
    "                stride=1,         \n",
    "                padding=2\n",
    "            ),\n",
    "            #Rectified linear unit\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )   \n",
    "            \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,      \n",
    "                out_channels=128,    \n",
    "                kernel_size=3,     \n",
    "                stride=1,         \n",
    "                padding=2\n",
    "            ),\n",
    "            #Rectified linear unit\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 128 -> num output channels from last conv block\n",
    "        # 5*4 -> spatial dimansion (h x w) arriving from the last layer (Maxpool2d)\n",
    "        # 5*4 can be found using torchsummary.summary(cnn.cuda(), input_size=(1, 64, 44))\n",
    "        self.linear = nn.Linear(in_features=128*5*4, out_features=10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "            \n",
    "    # forward method\n",
    "    def forward(self, input_data): \n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 66, 46]             160\n",
      "              ReLU-2           [-1, 16, 66, 46]               0\n",
      "         MaxPool2d-3           [-1, 16, 33, 23]               0\n",
      "            Conv2d-4           [-1, 32, 35, 25]           4,640\n",
      "              ReLU-5           [-1, 32, 35, 25]               0\n",
      "         MaxPool2d-6           [-1, 32, 17, 12]               0\n",
      "            Conv2d-7           [-1, 64, 19, 14]          18,496\n",
      "              ReLU-8           [-1, 64, 19, 14]               0\n",
      "         MaxPool2d-9             [-1, 64, 9, 7]               0\n",
      "           Conv2d-10           [-1, 128, 11, 9]          73,856\n",
      "             ReLU-11           [-1, 128, 11, 9]               0\n",
      "        MaxPool2d-12            [-1, 128, 5, 4]               0\n",
      "          Flatten-13                 [-1, 2560]               0\n",
      "           Linear-14                   [-1, 10]          25,610\n",
      "          Softmax-15                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 122,762\n",
      "Trainable params: 122,762\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.83\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 2.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # create a model\n",
    "    cnn = CNNNetwork()\n",
    "    # print summary of the model. use.cuda() to move the model to GPU\n",
    "    summary(cnn.cuda(), input_size=(1, 64, 44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
